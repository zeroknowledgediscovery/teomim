{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0db478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from teomim import teomim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2fee28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from quasinet.qnet import load_qnet\n",
    "from quasinet.qsampling import qsample\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import argparse\n",
    "from scipy.spatial.distance import cosine\n",
    "import pkg_resources\n",
    "import glob\n",
    "import random\n",
    "\n",
    "def bhattacharyya_coefficient(pmf1, pmf2):\n",
    "    return np.sum(np.sqrt((np.array(pmf1) * np.array(pmf2)).astype(float)))\n",
    "\n",
    "\n",
    "# Global variables\n",
    "global_model = None\n",
    "global_steps = None\n",
    "global_alpha = None\n",
    "\n",
    "def select_key_by_probability(prob_dict):\n",
    "    \"\"\"\n",
    "    Select a key from a dictionary where the keys are the items to be selected\n",
    "    and the values are the probabilities of each key.\n",
    "    \"\"\"\n",
    "    # Normalize the probabilities to ensure they sum up to 1\n",
    "    total = sum(prob_dict.values())\n",
    "    normalized_probs = {k: v / total for k, v in prob_dict.items()}\n",
    "\n",
    "    # Randomly select a key based on the probabilities\n",
    "    return random.choices(list(normalized_probs.keys()), weights=normalized_probs.values(), k=1)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def init_globals(model, steps, alpha):\n",
    "    global global_model, global_steps, global_alpha\n",
    "    global_model = model\n",
    "    global_steps = steps\n",
    "    global_alpha = alpha\n",
    "\n",
    "def parallel_qsample(seed):\n",
    "    return qsample(seed, global_model,\n",
    "                   steps=global_steps, alpha=global_alpha)\n",
    "\n",
    "def parallel_qsample_(seed):\n",
    "    \n",
    "    return qsample(seed, global_model,\n",
    "                   steps=global_steps, alpha=select_key_by_probability(global_alpha))\n",
    "\n",
    "def generate(modelpath, gz=True, alpha=1.3, outfile=None,\n",
    "             steps=200000, numworkers=11, num_patients=1000):\n",
    "    model = load_qnet(modelpath, gz=gz)\n",
    "    featurenames = np.array(model.feature_names)\n",
    "    seed = np.array([''] * len(featurenames)).astype('U100')\n",
    "\n",
    "    # Initialize global variables\n",
    "    init_globals(model, steps, alpha)\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=numworkers,\n",
    "                             initializer=init_globals,\n",
    "                             initargs=(model, steps, alpha)) as executor:\n",
    "        seeds = [seed for _ in range(num_patients)]\n",
    "        results = list(tqdm(executor.map(parallel_qsample, seeds),\n",
    "                            total=num_patients))\n",
    "\n",
    "    Sf = pd.DataFrame(results, columns=featurenames)\n",
    "    if outfile:\n",
    "        Sf.to_csv(outfile)\n",
    "    return Sf,model,featurenames\n",
    "\n",
    "\n",
    "def generate_dist(modelpath, gz=True, alpha={1.3:1}, outfile=None,\n",
    "             steps=200000, numworkers=11, num_patients=1000):\n",
    "    model = load_qnet(modelpath, gz=gz)\n",
    "    featurenames = np.array(model.feature_names)\n",
    "    seed = np.array([''] * len(featurenames)).astype('U100')\n",
    "\n",
    "    # Initialize global variables\n",
    "    init_globals(model, steps, alpha)\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=numworkers,\n",
    "                             initializer=init_globals,\n",
    "                             initargs=(model, steps, alpha)) as executor:\n",
    "        seeds = [seed for _ in range(num_patients)]\n",
    "        results = list(tqdm(executor.map(parallel_qsample_, seeds),\n",
    "                            total=num_patients))\n",
    "\n",
    "    Sf = pd.DataFrame(results, columns=featurenames)\n",
    "    if outfile:\n",
    "        Sf.to_csv(outfile)\n",
    "    return Sf,model,featurenames\n",
    "\n",
    "\n",
    "\n",
    "def evaluate__(df, code_prefixes, suffix=None, age_prefix=''):\n",
    "    if not isinstance(code_prefixes, (np.ndarray, list)):\n",
    "        code_prefixes = [code_prefixes]\n",
    "\n",
    "    valid_rows = np.array([True] * df.index.size)\n",
    "\n",
    "    if suffix is not None and not isinstance(suffix, (np.ndarray, list)):\n",
    "        suffix = [suffix]\n",
    "\n",
    "    for code_prefix in code_prefixes:\n",
    "        af = df[[col for col in df.columns if col.startswith(code_prefix+'_'+age_prefix)]]\n",
    "        af=af.replace('.','').replace('',np.nan)\n",
    "\n",
    "        if suffix:\n",
    "            for s in suffix:\n",
    "                af = af.replace(s, np.nan)\n",
    "        # Determine if any non-NaN values exist in the row after handling suffixes\n",
    "        current_valid = af.notna().sum(axis=1).astype(bool)\n",
    "        # Perform an AND operation between the currently valid rows and the overall valid_rows\n",
    "        valid_rows &= current_valid\n",
    "\n",
    "    num_valid_rows = valid_rows.sum()\n",
    "\n",
    "    return num_valid_rows / df.index.size\n",
    "\n",
    "class teomim:\n",
    "    def __init__(self, modelpath=None, gz=True, alpha=1.3,\n",
    "                 outfile=None, steps=200000,\n",
    "                 numworkers=11,\n",
    "                 num_patients=1000,seed=None):\n",
    "        self.modelpath = modelpath\n",
    "        self.gz = gz\n",
    "        self.alpha = alpha\n",
    "        self.outfile = outfile\n",
    "        self.steps = steps\n",
    "        self.numworkers = numworkers\n",
    "        self.num_patients = num_patients\n",
    "        self.seed = None\n",
    "        self.patients = None\n",
    "        self.EVAL_PREFIXES={'I10':.7,'I25':.4,'I50':.25,'E11':.46,\n",
    "                            'E66':.3,'I63':.4,'G20':.15,'F32':.5,\n",
    "                            'F41':.4,'M81':.25,'J44':.55,'J84':0.005}\n",
    "\n",
    "        self.asset_path = pkg_resources.resource_filename('teomim', 'assets/')\n",
    "\n",
    "    def set_modelpath(self,specifier,path=None,gz=None):\n",
    "        if gz:\n",
    "            self.gz = gz\n",
    "        if not path:\n",
    "            self.modelpath = glob.glob(self.asset_path+'/*'+specifier+'*')[0]\n",
    "        else:\n",
    "            self.modelpath = specifier\n",
    "        return \n",
    "        \n",
    "    def load(self,patientdata):\n",
    "        self.patients = pd.read_csv(patientdata)\n",
    "        \n",
    "    def generate(self):\n",
    "        self.patients,self.model,self.featurenames\\\n",
    "            = generate(modelpath=self.modelpath,\n",
    "                       gz=self.gz, alpha=self.alpha,\n",
    "                       outfile=self.outfile,\n",
    "                       steps=self.steps,\n",
    "                       numworkers=self.numworkers,\n",
    "                       num_patients=self.num_patients)\n",
    "\n",
    "    def set_model(self): \n",
    "        self.model = load_qnet(self.modelpath, gz=self.gz)\n",
    "        self.featurenames = np.array(self.model.feature_names)\n",
    "\n",
    "\n",
    "    def evaluate(self,EVAL=None):\n",
    "\n",
    "        if EVAL is None:\n",
    "            EVAL = self.EVAL_PREFIXES\n",
    "        elif not isinstance(EVAL, dict) or not all(isinstance(key,\n",
    "                                                              str)\n",
    "                                                   and isinstance(value,\n",
    "                                                                  float)\n",
    "                                                   for key, value in EVAL.items()):\n",
    "            raise ValueError(\"EVAL must be a dictionary\\\n",
    "            with keys as strings and values as floats.\")\n",
    "        \n",
    "            \n",
    "        self.evaldf = pd.DataFrame([evaluate__(self.patients,x)\n",
    "                                    for x in EVAL.keys()],\n",
    "                                   list(EVAL.keys()),\n",
    "                                   columns=[\n",
    "                                       'prevalences']).assign(\n",
    "                                           prevalence_expected\n",
    "                                =(np.array(EVAL.values())))\n",
    "\n",
    "        return self.evaldf.copy()\n",
    "\n",
    "        \n",
    "    def quality(self,df=None):\n",
    "\n",
    "        if not df:\n",
    "            df=self.evaldf\n",
    "            \n",
    "        if df.shape[1] != 2:\n",
    "            raise ValueError(\"DataFrame should have exactly\\\n",
    "            two columns representing two PMFs.\")\n",
    "\n",
    "        # Extracting PMFs from DataFrame columns\n",
    "        pmf1 = df.iloc[:, 0]\n",
    "        pmf2 = df.iloc[:, 1]\n",
    "\n",
    "        # Normalize PMFs to ensure they sum to 1\n",
    "        pmf1 = np.array(pmf1) / np.sum(pmf1)\n",
    "        pmf2 = np.array(pmf2) / np.sum(pmf2)\n",
    "\n",
    "        # Calculate Bhattacharyya Coefficient\n",
    "        b_coeff = bhattacharyya_coefficient(pmf1, pmf2)*100\n",
    "\n",
    "        return np.round(b_coeff,2)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54d3d805",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'teomim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'teomim'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3021734/4086797208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m P=teomim(modelpath='./twin_models/FULL_QNET.joblib',alpha={1.3:1},\n\u001b[0m\u001b[1;32m      2\u001b[0m                  gz=False,outfile='out100.csv',num_patients=50)\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#P.load('./twin_data/output.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3021734/2361231171.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, modelpath, gz, alpha, outfile, steps, numworkers, num_patients, seed)\u001b[0m\n\u001b[1;32m    138\u001b[0m                             'F41':.4,'M81':.25,'J44':.55,'J84':0.005}\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'teomim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'assets/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_modelpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspecifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mresource_filename\u001b[0;34m(self, package_or_requirement, resource_name)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresource_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_or_requirement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0;34m\"\"\"Return a true filesystem path for specified resource\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m         return get_provider(package_or_requirement).get_resource_filename(\n\u001b[0m\u001b[1;32m   1212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__loader__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'teomim'"
     ]
    }
   ],
   "source": [
    "P=teomim(modelpath='./twin_models/FULL_QNET.joblib',alpha={1.3:1},\n",
    "                 gz=False,outfile='out100.csv',num_patients=50)\n",
    "\n",
    "#P.load('./twin_data/output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "P.generate_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8df5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ef=P.evaluate()\n",
    "print(ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(P.quality())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ef.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212985e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
