<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>zedstat.zedstat API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#666666;background-color:black;//mix-blend-mode:difference;color:#bbbbbb;z-index:3}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#66bb66;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#66FF66}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:transparent;padding:1px 4px;color:#FFA500;overflow-wrap:break-word}h1 code{background:transparent}pre{overflow-wrap:break-word;background:#111111;word-wrap:break-word;border:0;border-top:1px solid #666;border-bottom:1px solid #666;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#333333;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#aaeeaa;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;color:#bbbbbb;background-color:black;overflow-wrap:break-word}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>zedstat.zedstat</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pandas as pd
import numpy as np
from sklearn.metrics import auc
from scipy.interpolate import UnivariateSpline

class processRoc(object):
    &#34;&#34;&#34;process ROC datafile&#34;&#34;&#34;

    def __init__(self,
                 df=None,
                 fprcol=&#39;fpr&#39;,
                 tprcol=&#39;tpr&#39;,
                 thresholdcol=&#39;threshold&#39;,
                 prevalence=None,
                 order=2,
                 total_samples=None,
                 positive_samples=None,
                 alpha=0.05):

        &#34;&#34;&#34;Initialization

        Args:
            df (pandas.DataFrame): dataframe with columns tabulating fpr, tpr, and optionally threshold values
            fprcol (str): string name of fpr column
            tprcol (str): string name of tpr column
            thresholdcol (str): string name of threshold column
            prevalence (float): prevalence of positive cases in population (need not be the data ratio)
            order (int): order of polynomial/spline for smoothing
            total_samples (int): total number of samples in the original data
            positive samples (int): number of positive cases in the original data
            alpha (float): significance level e.g. 0.05
        &#34;&#34;&#34;
        
        #print(&#39;local version 1&#39;)
        
        if df.index.name==fprcol:
            self.df=df.copy()
        else:
            if fprcol in df.columns:
                self.df=df.set_index(fprcol).copy()
            else:
                raise(&#39;fpr not in columns or index&#39;)
        self.thresholdcol = thresholdcol
            
        if thresholdcol not in self.df.columns:
            self.thresholdcol=None

        self.df = self.df.sort_values(&#39;fpr&#39;)
            
        self.fprcol = fprcol
        self.tprcol = tprcol
        self.raw_df = self.df.copy()
        self.prevalence = prevalence
        self.order = order
        self.df_lim = {}
        self._auc = {&#39;U&#39;:[],&#39;L&#39;:[]}
        self.total_samples = total_samples
        self.positive_samples = positive_samples
        self.alpha = alpha
        
        self.df=self.df.groupby(self.fprcol).max().reset_index()

        
    def get(self):
        &#39;&#39;&#39;
        return dataframe currently in class

        Returns:
            pandas.DataFrame 
        &#39;&#39;&#39;
        return self.df.copy()
    

    def nominal_auc(self):
        &#39;&#39;&#39;
        calculate nominal auc
        &#39;&#39;&#39;
        from sklearn.metrics import auc
        self._auc[&#39;nominal&#39;]=auc(self.df.index.values,self.df.tpr.values)
        return

    
    def auc(self,
            total_samples=None,
            positive_samples=None,
            alpha=None):
        &#39;&#39;&#39;
        calculate auc with confidence bounds. As default, the arguments are read from class initializtion.

        Args:
            total_samples (int): total number fo samples, default None
            positive_samples (int): number fo positive samples, default None
            alpha (float): significance level, default None

        Returns:
            float: nominal auc
            float: upper bound
            float: lower bound
        
        &#39;&#39;&#39;
        self.nominal_auc()
        self._auc[&#39;U&#39;]=[]
        self._auc[&#39;L&#39;]=[]
        
        self.getBounds(total_samples=total_samples,
                positive_samples=positive_samples,
                alpha=alpha)
        self.__auc_cb2(total_samples=total_samples,
                positive_samples=positive_samples,
                alpha=alpha)
        return self._auc[&#39;nominal&#39;], self._auc[&#39;U&#39;].min(), self._auc[&#39;L&#39;].max()

    
    def __convexify(self):
        &#39;&#39;&#39;
        compute convex hull of the roc curve
        &#39;&#39;&#39;
        #print(self.df)
        from scipy.spatial import ConvexHull
        if self.df.index.name==self.fprcol:
            rf=self.df
        else:
            if self.fprcol in self.df.columns:
                rf=self.df.set_index(self.fprcol)#.drop(&#39;threshold&#39;,axis=1)
            else:
                raise(&#39;fpr not in columns or index&#39;)

        rf = rf.reset_index()
        rf=pd.concat([rf,pd.DataFrame({self.fprcol:0, self.tprcol:0},index=[0])])
        rf=pd.concat([rf,pd.DataFrame({self.fprcol:1, self.tprcol:0},index=[0])])
        rf=pd.concat([rf,pd.DataFrame({self.fprcol:1, self.tprcol:1},index=[0])])
        
        rf=rf.drop_duplicates()
        rf=rf.sort_values(self.fprcol)
        rf=rf.sort_values(self.tprcol)

        pts=rf[[self.fprcol,self.tprcol]].values

        #print(pts)
        
        if len(pts)&lt;3:
            rf_=rf.copy()
            rf_.columns=[self.tprcol,self.fprcol]
            rf_=rf_.sort_values(self.fprcol)
            rf_=rf_.sort_values(self.tprcol)
            self.df=rf_.set_index(self.fprcol).copy()
            return #self.df
        
        hull = ConvexHull(pts)
        rf_=pd.DataFrame(pts[hull.vertices, 0], pts[hull.vertices, 1]).reset_index()
        rf_.columns=[self.tprcol,self.fprcol]
        rf_ = rf_.set_index(self.fprcol)
        
        rf_ = rf_.drop(1.0).sort_index()
        rf_.loc[1.0]=1.0
        
        self.df=rf_.copy()
        return 


    def smooth(self,
               STEP=0.0001,
               interpolate=True,
               convexify=True):
        &#39;&#39;&#39;
        smooth roc curves and update processRoc.df which is accessible using processRoc.get()

        Args:
            STEP (float): smooting step, default 0.0001
            interpolate (bool): if True, interpolate missing values, default True
            convexify (bool): if True, replace ROC with convex hull, default True
        &#39;&#39;&#39;
        self.df=self.raw_df.copy()
        VAR=self.fprcol
        df_=self.df.reset_index()
        DF=pd.concat([pd.DataFrame(
            df_[df_[VAR].between(i,i+STEP)].max()).transpose()
                      for i in np.arange(0,1,STEP)]).set_index(VAR)
        DF=DF.dropna()
        DF.loc[0]=pd.Series([],dtype=float) 
        DF.loc[1]=pd.Series([],dtype=float) 
        DF.loc[0,&#39;tpr&#39;]=0
        DF.loc[1,&#39;tpr&#39;]=1
        
        DF=DF.sort_index()
        if interpolate:
            DF=DF.interpolate(limit_direction=&#39;both&#39;,method=&#39;spline&#39;,order=self.order)
            DF[DF &lt; 0] = 0
            self.df=DF
        if convexify:
            self.__convexify()
        return 

    
    def allmeasures(self,prevalence=None,interpolate=False):
        &#39;&#39;&#39;
        compute accuracy, PPV, NPV, positive and negative likelihood ratios, and update processRoc.df, which can be accessed using processRoc.get()

        Args:
            prevalence (float): prevalence od positive cases in population
            interpolate (bool): if True interpolate missing values, default False
        &#39;&#39;&#39;
        if prevalence is not None:
            p=prevalence
            self.prevalence=p
        else:
            p=self.prevalence
        if p is None:
            raise(&#39;prevalence undefined&#39;)
        df__=self.df.copy()
        if self.fprcol == df__.index.name:
            df__=df__.reset_index()
            df__[&#39;ppv&#39;]=1/(1+((df__.fpr/df__.tpr)*((1/p)-1)))
            df__[&#39;acc&#39;]=p*df__.tpr + (1-p)*(1-df__.fpr)
            df__[&#39;npv&#39;]=1/(1+((1-df__.tpr)/(1-df__.fpr))*(1/((1/p)-1)))
            df__[&#39;LR+&#39;]=(df__.tpr)/(df__.fpr)
            df__[&#39;LR-&#39;]=(1-df__.tpr)/(1-df__.fpr)
        else:
            assert(&#39;set fpr as index&#39;)
            
            
        df__=df__.set_index(self.fprcol)

        #display(df__)
        df__=df__.replace(np.inf,np.nan)
        #display(df__)


        
        if interpolate:
            try:
                df__=df__.interpolate(limit_direction=&#39;both&#39;,method=&#39;spline&#39;,order=self.order)
            except:
                print(&#39;interpolation failed&#39;)

 
        #display(df__)
        
        if self.thresholdcol is not None:
            if self.thresholdcol not in df__.columns:
                df__=df__.join(self.raw_df[self.thresholdcol])
        self.df=df__
        self.__correctPPV()
        self.df[self.df &lt; 0] = 0


        self.df=self.df.reset_index().groupby(&#39;fpr&#39;).max()
        self.df.ppv=UnivariateSpline(self.df.index.values,self.df.ppv.values,k=1,s=None)(self.df.index.values)
        self.df[self.df &lt; 0] = 0

        #display(self.df)
        
        return #self.df


    def __correctPPV(self,df=None):
        &#39;&#39;&#39;
        make ppv monotonic
        &#39;&#39;&#39;
        if &#39;ppv&#39; not in self.df.columns:
            return

        if df is None:
            df__=self.df
        else:
            df__=df.copy()
            
        
        #df__.loc[0].ppv=1.0
        #df__.loc[1].ppv=0.0
        arr=df__.ppv.values
        a_=[]
        for i in np.arange(len(arr)-1):
            if arr[i+1]&gt;arr[i]:
                a_.append(1.05*arr[i+1])
            else:
                a_.append(arr[i])
        a_.append(arr[-1])

        
        df__.ppv=a_
        #df__.loc[0].ppv=1.0
        #df__.loc[1].ppv=0.0
        
        
        return df__


    def scoretoprobability(self, score, regen=True, **kwargs):
        &#39;&#39;&#39;
        Map computed score to probability of sample being in the positive class.
        This is simply the PPV corresponding to the threshold which equals the score.
        Now supports both single scores and lists/numpy arrays of scores.

        Args:
            score (float or list or numpy.ndarray): computed score(s)
            regen (bool): if True, regenerate roc curve
            kwargs (dict): values passed for regeneration of smoothed roc

        Return:
            float or numpy.ndarray representing probability of being in positive cohort
        &#39;&#39;&#39;

        if score is None:
            return None

        if regen:
            STEP = 0.01
            precision = 3
            interpolate = True

            STEP = kwargs.get(&#39;STEP&#39;, STEP)
            precision = kwargs.get(&#39;precision&#39;, precision)
            interpolate = kwargs.get(&#39;interpolate&#39;, interpolate)

            self.smooth(STEP=STEP)
            self.allmeasures(interpolate=interpolate)
            self.usample(precision=precision)

        df = self.get()
        if &#39;threshold&#39; not in df.columns:
            raise ValueError(&#39;Threshold not in columns or index&#39;)
        if &#39;ppv&#39; not in df.columns:
            raise ValueError(&#39;PPV not in columns or index&#39;)

        def compute_val(score):
            if score is None:
                return None
            if score &gt; df.threshold.max():
                val = df.ppv.values.max()
            else:
                val = df[df.threshold &gt; score].ppv.tail(1).values[0]
            return (val - df.ppv.values.min()) / (df.ppv.values.max() - df.ppv.values.min())

        if isinstance(score, (list, np.ndarray)):
            return np.array([compute_val(s) for s in score])
        else:
            return compute_val(score)

    
    def usample(self,
                df=None,
                precision=3):
        &#39;&#39;&#39;
        make performance measures estimated at regular intervals of false positive rate

        Args:
            df (pandas.DataFrame): dataframe woth performance values, fpr as index. default: None, when the dataframe entered at initialization is used
            precision (int): number of digits after decismal point used to sample fpr range
        
        Returns:
            pandas.DataFrame: uniformly sampled performance dataframe
        &#39;&#39;&#39;
        step=10**(-precision)
        fpr=[np.round(x,precision) for x in np.arange(0,1+step,step)]
        if df is None:        
            fpr_=[x for x in fpr if x not in self.df.index]
        else:
            fpr_=[x for x in fpr if x not in df.index]

        if df is None:
            df___=self.df.copy()
        else:
            df___=df.copy()
            
        for x in fpr_:
            df___.loc[x]=pd.Series([],dtype=float) 
        df___=df___.sort_index().interpolate()
        
        df___=df___.loc[fpr]        
        if df is None:
            self.df=df___

        return df___


    def __getDelta(self,
                 total_samples=None,
                 positive_samples=None,
                 alpha=None):
        &#39;&#39;&#39;
        confidence bounds on specificity and sensitivity using Wald-type approach
        &#39;&#39;&#39;
        if total_samples is None:
            total_samples=self.total_samples
        if positive_samples is None:
            positive_samples = self.positive_samples
        if alpha is None:
            alpha=self.alpha
            
        n=total_samples
        n_pos=positive_samples
        
        if self.fprcol not in self.df.columns:
            if self.fprcol != self.df.index.name:
                return
        if self.tprcol not in self.df.columns:
            return
        
        import scipy.stats as stats
        z=stats. norm. ppf(1 - (alpha/2))
        delta_=pd.DataFrame()
        df_=self.df.copy()
        if self.fprcol == df_.index.name:
            df_=df_.reset_index()
            delta_[&#39;fprdel&#39;]=z*np.sqrt((df_.fpr*(1-df_.fpr))/n)
            delta_[&#39;tprdel&#39;]=z*np.sqrt((df_.tpr*(1-df_.tpr))/n_pos)
            self.delta_=delta_
        return 

    
    def getBounds(self,
                  total_samples=None,
                  positive_samples=None,
                  alpha=None,
                  prevalence=None):
        &#39;&#39;&#39;
        compute confidence bounds on performance measures

        Args:
            total_samples (int): total number fo samples, default None
            positive_samples (int): number fo positive samples, default None
            alpha (float): significance level, default None
            prevalence (float): prevalence of positive cases in population, default None

        &#39;&#39;&#39;
        self.__getDelta(total_samples=total_samples,
                 positive_samples=positive_samples,
                      alpha=alpha)

        if prevalence is None:
            p=self.prevalence
        else:
            p=prevalence
        
        if p is None:
            raise(&#39;prevalence undefined&#39;)

        for direction in [&#39;U&#39;,&#39;L&#39;]:
            df__=self.df.copy().reset_index()

            if direction==&#39;U&#39;:
                df__.tpr=df__.tpr+self.delta_.tprdel
                #df__.fpr=df__.fpr-self.delta_.fprdel
            else:
                df__.tpr=df__.tpr-self.delta_.tprdel
                #df__.fpr=df__.fpr+self.delta_.fprdel
                
            df__[&#39;ppv&#39;]=1/(1+((df__.fpr/df__.tpr)*((1/p)-1)))
            df__[&#39;acc&#39;]=p*df__.tpr + (1-p)*(1-df__.fpr)
            df__[&#39;npv&#39;]=1/(1+((1-df__.tpr)/(1-df__.fpr))*(1/((1/p)-1)))
            df__[&#39;LR+&#39;]=(df__.tpr)/(df__.fpr)
            df__[&#39;LR-&#39;]=(1-df__.tpr)/(1-df__.fpr)

            df__=df__.replace(np.inf,np.nan)

            
            df__=df__.interpolate(limit_direction=&#39;both&#39;,method=&#39;spline&#39;,
                                  order=self.order).set_index(self.fprcol)
            df__[df__ &lt; 0] = 0

            self.df_lim[direction]=self.__correctPPV(df__)
            
            if direction==&#39;U&#39;:
                self._auc[direction]=np.array([np.append(self._auc[direction],
                                                auc(df__.index.values,
                                                    df__.tpr.values)).min()])
            if direction==&#39;L&#39;:
                self._auc[direction]=np.array([np.append(self._auc[direction],
                                                auc(df__.index.values,
                                                    df__.tpr.values)).max()])


            # adjust datframe to cneter of upper and lowwr bounds    
        #self.df=(self.df_lim[&#39;U&#39;]+ self.df_lim[&#39;L&#39;] )/2
        #self.__correctvalues()
        return 

    def __correctvalues(self):
        #ppv
        if &#39;ppv&#39; in self.df.columns:
            self.df.ppv[self.df.ppv&gt;1]=1.0
        if &#39;npv&#39; in self.df.columns:
            self.df.npv[self.df.npv&gt;1]=1.0
        if &#39;LR-&#39; in self.df.columns:
            self.df[&#39;LR-&#39;][self.df[&#39;LR-&#39;]&gt;1]=1.0
            

    def __auc_cb2(self,
                total_samples=None,
                positive_samples=None,
                alpha=None):
        &#39;&#39;&#39;
        compute auc confidence bounds using Danzig bounds

        Args:
            total_samples (int): total number fo samples, default None
            positive_samples (int): number fo positive samples, default None
            alpha (float): significance level, default None
        &#39;&#39;&#39;
        if total_samples is None:
            total_samples=self.total_samples
        if positive_samples is None:
            positive_samples = self.positive_samples
        if alpha is None:
            alpha=self.alpha

        n=total_samples
        n_pos=positive_samples


        if &#39;nominal&#39; not in self._auc.keys():
            assert(&#39;calculate nominal auc first&#39;)
            
        import scipy.stats as stats
        auc=self._auc[&#39;nominal&#39;]
        z=stats. norm. ppf(1 - (alpha/2))

        eta=1+(n_pos/(z*z))
        b=(auc-.5)/eta
        auc_U=auc+b+ (1/eta)*np.sqrt((auc-.5)**2 + (auc*(1-auc)*eta))
        auc_L=auc+b- (1/eta)*np.sqrt((auc-.5)**2 + (auc*(1-auc)*eta))

        self._auc[&#39;L&#39;]=np.array([np.append(self._auc[&#39;L&#39;],auc_L).max()])
        self._auc[&#39;U&#39;]=np.array([np.append(self._auc[&#39;U&#39;],auc_U).min()])

        return

    
    def operating_zone(self,
                       n=1,
                       LRplus=10,
                       LRminus=0.6):
        &#39;&#39;&#39;
        compute the end points of the operating zone, 
        one for maximizing precions, and one for maximizing sensitivity

        Args:
            n (int): number of operting points per condition returned, default 1
            LRplus (float): lower bound on positive likelihood ratio, default 10.0
            LRminus (float): upper bound on negative likelihood ratio, default 0.6

        &#39;&#39;&#39;
        wf=self.df.copy()
        
        opf=pd.concat([wf[(wf[&#39;LR+&#39;]&gt;LRplus)
                          &amp; (wf[&#39;LR-&#39;]&lt;LRminus) ]\
                       .sort_values(&#39;ppv&#39;,ascending=False).head(n),
                       wf[(wf[&#39;LR+&#39;]&gt;LRplus)
                          &amp; (wf[&#39;LR-&#39;]&lt;LRminus) ]\
                       .sort_values(&#39;tpr&#39;,ascending=False).head(n)])

        if opf.empty:
            self._operating_zone=opf.copy()
            return #self._operating_zone.copy()
        self._operating_zone=opf.reset_index()
        self._operating_zone.index=[&#39;high precision&#39;]*n + [&#39;high sensitivity&#39;]*n
        return #self._operating_zone.copy()

    
    def samplesize(self,
                   delta_auc=0.1,
                   target_auc=None,
                   alpha=None):
        &#39;&#39;&#39;
        estimate sample size for atataing auc bound under given significance level

        Args:
            delta_auc (float): maximum perturbation from estimated auc, default 0.1
            target_auc (float): if None, using estimate current nominal auc
            alpha (float): significanec level. If None use processRoc.alpha

        Returns:
            float: minimum sample size
        &#39;&#39;&#39;
        if alpha is None:
            alpha=self.alpha

        if target_auc is None:
            if &#39;nominal&#39; not in self._auc.keys():
                self.auc()
            target_auc=self._auc[&#39;nominal&#39;]
            
        import scipy.stats as stats
        z=stats. norm. ppf(1 - (alpha/2))
        required_npos = (z*z)*target_auc*(1-target_auc)/(delta_auc*delta_auc)

        return required_npos

    def pvalue(self,
               delta_auc=0.1,
               twosided=True):
        &#39;&#39;&#39;
        compute p-value for given auc bounds

        Args:
            delta_auc (float): maximum perturbation from estimated auc, default 0.1
            twosided (bool): one sided or twosided confidence bounds

        Returns:
            float: pvalue for the null hypothesis that estimated nominal auc is lower by more than delta_auc
        &#39;&#39;&#39;
        if &#39;nominal&#39; not in self._auc.keys():
            self.auc()
        auc=self._auc[&#39;nominal&#39;]
            
        import scipy.stats as stats
        z=np.sqrt(self.positive_samples/(auc*(1-auc)/(delta_auc*delta_auc)) )
        pvalue=stats.norm.sf(abs(z))

        if twosided:
            pvalue=2*pvalue
        return pvalue
    
    
    def interpret(self,
                  fpr=0.01,
                  number_of_positives=10,
                  five_yr_survival=None,
                  cancer=True,
                  TDELTA=1,
                  diagnosis_probs=None,
                  survival_probs=None,
                  factor=1):
        &#39;&#39;&#39;
        generate simple interpretation of inferred model, based on a number of positive cases

        Args:
            fpr (float): the false psotive rate or 1-specificity of the operating point
            number_of_positives (int): interpret assuming this many positive cases, default 10
            five_yr_survival (float): fraction not experiencing severe event after 5 years (default: None)
            factor (float): fraction of TP who avert the severe outcome due to correct screen
        &#39;&#39;&#39;
        wf=self.df.copy()
                
        wf.loc[fpr]=pd.Series([],dtype=float)
        wf=wf.sort_index().interpolate(method=&#39;spline&#39;,order=self.order,limit_direction=&#39;both&#39;)
        
        row=wf.loc[fpr]

#        POS=number_of_positives
#        TP=POS*row.tpr
#        FP = TP*((1/row.ppv) -1)
#        NEG=FP/fpr
#        TOTALFLAGS=TP+FP
#        FN=POS-TP
#        TN=POS/self.prevalence

        #factor=0.21*(0.95-0.69) + 0.08*(0.95-0.17)
        #factor=0.33*(0.95-0.17)

        POS=number_of_positives
        NEG=POS*(1-self.prevalence)*(1/self.prevalence)
        TP=POS*row.tpr
        TOTALFLAGS=TP/row.ppv
        FP=TOTALFLAGS-TP
        FN=POS-TP
        TN=NEG-FP
        if five_yr_survival is not None:
            NNS=TOTALFLAGS/(TP*factor*(1- five_yr_survival))
        else:
            if cancer:
                eta=getEta(survival_probs,diagnosis_probs,TDELTA=TDELTA)
                PPV= (TP/(POS+NEG)) * self.prevalence / ((TP/(POS)) * self.prevalence + (FP/NEG) * (1 - self.prevalence)) 
                NNS=1/(eta*PPV)
            else: 
                NNS=np.nan

            
        resdf=pd.DataFrame.from_dict({&#34;POS&#34;:np.round(POS),&#34;TP&#34;:np.round(TP),
                                      &#34;FP&#34;:np.round(FP),&#34;NEG&#34;:np.round(NEG),
                                      &#34;FLAGS&#34;:np.round(TOTALFLAGS),&#34;FN&#34;:np.round(FN),
                                      &#34;TN&#34;:np.round(TN),
                                      &#34;NNS&#34;:np.round(NNS),
                                      &#34;FLAGGED_FRACTION&#34;:np.round(TOTALFLAGS/(POS+NEG),
                                                                  2)},orient=&#39;index&#39;,columns=[&#39;estimates&#39;])
        
        rf=pd.DataFrame({&#39;pos&#39;:np.round(POS),
                      &#39;flags&#39;:int(np.round(TOTALFLAGS)),
                      &#39;tp&#39;:int(np.round(TP)),
                      &#39;fp&#39;:int(np.round(FP)),
                      &#39;fn&#39;:int(np.round(FN)),
                      &#39;tn&#39;:int(np.round(TN))},index=[&#39;numbers&#39;])

        pos=rf.pos.values[0]
        flags=rf[&#39;flags&#39;].values[0]
        fp=rf[&#39;fp&#39;].values[0]
        tp=rf[&#39;tp&#39;].values[0]
        fn=rf[&#39;fn&#39;].values[0]

        txt=[f&#34;For every {pos} positive instances&#34;,
             f&#34;we raise {flags} flags,&#34;,
             f&#34;out of which {tp} are true positives&#34;,
             f&#34;{fp} are false alarms&#34;,
             f&#34;{fn} cases are missed&#34;]
        if five_yr_survival is not None:
            txt.append(f&#34;Number needed to screen is {NNS}&#34;)
        if cancer:
            txt.append(f&#34;Number needed to screen is {NNS}&#34;)
        
            

        return rf,txt,resdf




def genroc(df,
           risk=&#39;predicted_risk&#39;,
           target=&#39;target&#39;,
           steps=1000,
           TARGET=[1],
           outfile=None):
    &#39;&#39;&#39;
    compute roc curve from raw observation of risk-target information on samples

    Args:
        df (pandas.DataFrame): dataframe of raw samples identified as positive or negative with computed risk
        target (str): name of target column
        risk (str): name of risk column
        TARGET (list): list of values of target column that define the positive case, default [1]
        steps (int): steps between max and min of risk value, default 1000
        outfile (str): write datafraem with fpr tpr threshold, default None

    Returns:
        pandas.DataFrame: roc dataframe
        int: total number of samples
        int: total number of positive samples
    &#39;&#39;&#39;
    threshold={}
    df_=df[[risk,target]].rename(columns={risk:&#39;risk&#39;,target:&#39;target&#39;})
    delta=(df_.risk.max()-df_.risk.min())/steps
    for r in np.arange(df_.risk.min(),df_.risk.max()+delta,delta):
        #print(r)
        fn=df_[(df_.risk&lt;r) &amp; df_.target.isin(TARGET)].index.size
        tp=df_[(df_.risk&gt;=r) &amp; df_.target.isin(TARGET)].index.size
        fp=df_[(df_.risk&gt;=r) &amp; ~df_.target.isin(TARGET)].index.size
        tn=df_[(df_.risk&lt;r) &amp; ~df_.target.isin(TARGET)].index.size
        threshold[r]={&#39;tp&#39;:tp,&#39;fp&#39;:fp,&#39;tn&#39;:tn,&#39;fn&#39;:fn}
        
    xf=pd.DataFrame.from_dict(threshold).transpose()
    xf.index.name=&#39;threshold&#39;
    
    xf=xf.assign(tpr=(xf.tp)/(xf.tp+xf.fn)).assign(fpr=(xf.fp)/(xf.fp+xf.tn))
    xf=xf[[&#39;fpr&#39;,&#39;tpr&#39;]].reset_index()#.set_index(&#39;fpr&#39;)
    
    if outfile is not None:
        xf.to_csv(outfile)
    return xf,df_.index.size,df_[df_.target.isin(TARGET)].index.size    



def pipeline(df,
            risk=&#39;predicted_risk&#39;,
            target=&#39;target&#39;,
            steps=1000,
            TARGET=[1],
            order=3,
            alpha=0.05,
            prevalence=.002,
            precision=3,
            outfile=None):
    rf,total_samples,positive_samples=genroc(df,risk=risk,
                                             target=target,
                                             TARGET=TARGET)
    zt=processRoc(rf,
                  order=order, 
                  total_samples=total_samples,
                  positive_samples=positive_samples,
                  alpha=alpha,
                  prevalence=prevalence)
    
    zt.smooth(STEP=0.001)
    zt.allmeasures(interpolate=True)
    zt.usample(precision=precision)
    zt.getBounds()

    df_=zt.get()
    df_u=zt.df_lim[&#39;U&#39;]
    df_l=zt.df_lim[&#39;L&#39;]

    df_=df_.join(df_u,rsuffix=&#39;_upper&#39;).join(df_l,rsuffix=&#39;_lower&#39;)

    if outfile is not None:
        df_.to_csv(outfile)

    return df_,zt.auc()


def score_to_probability(scores,df,
                  prevalence,
                  total_samples,
                  positive_samples,
                  alpha=0.05):
    &#39;&#39;&#39;
    returns score to probability and upper and lower bound fast 
    and robust, standalone.
    implements: Statist. Med. 2007; 26:3258–3273
    DOI: 10.1002/sim.2812
    Prevalence-dependent diagnostic accuracy measures
    Jialiang Li, Jason P. Fine and Nasia Safdar
    &#39;&#39;&#39;
    from scipy.stats import norm
    z = norm.ppf(1 - alpha / 2)
    se=df.tpr
    sp=1-df.fpr
    var_se = se * (1 - se) / positive_samples
    var_sp = sp * (1 - sp) / (total_samples - positive_samples)
    df[&#39;g1&#39;]= (1 - sp) / se
    sigma_1 = np.sqrt(total_samples * (1 - sp)**2 * var_se / (se**4) + total_samples * var_sp / (se**2))
    df[&#39;ci_g1&#39;] =  z * (sigma_1 / np.sqrt(total_samples))
    df[&#39;ppv&#39;] = se * prevalence / (se * prevalence + (1 - sp) * (1 - prevalence))
    df[&#39;ppv_lower&#39;] = 1/(1+ ((1-prevalence)/prevalence)*(df[&#39;g1&#39;]-df[&#39;ci_g1&#39;]))
    df[&#39;ppv_upper&#39;] = 1/(1+ ((1-prevalence)/prevalence)*(df[&#39;g1&#39;]+df[&#39;ci_g1&#39;]))
    df=df.dropna().drop([&#39;g1&#39;,&#39;ci_g1&#39;],axis=1)
    
    return [df[df.threshold&gt;=score].tail(1)[[&#39;ppv&#39;,&#39;ppv_upper&#39;,&#39;ppv_lower&#39;]].round(2).values[0] for score in scores]



def getTime(s,time_5_year_exp=5,target_survival_exp=.99):
    lambd_exp = -np.log(s) / time_5_year_exp
    return -np.log(target_survival_exp) / lambd_exp

# construct step function
def dx_prob(t,diagnosis_probs,survival_probs):
    stage_time = [getTime(survival_probs[0])-getTime(survival_probs[1]),
                  getTime(survival_probs[1])-getTime(survival_probs[2]),
                  getTime(survival_probs[2])] 

    if t &lt; stage_time[0]-stage_time[1]:
        return diagnosis_probs[0]
    if t &lt; stage_time[0]-stage_time[2]:
        return diagnosis_probs[1]
    if t &gt; stage_time[0]-stage_time[2]:
        return diagnosis_probs[2]
# construct step function
def s_prob(t,survival_probs):
    stage_time = [getTime(survival_probs[0])-getTime(survival_probs[1]),
                  getTime(survival_probs[1])-getTime(survival_probs[2]),
                  getTime(survival_probs[2])] 
    
    if t &lt; stage_time[0]-stage_time[1]:
        return survival_probs[0]
    if t &lt; stage_time[0]-stage_time[2]:
        return survival_probs[1]
    if t &gt; stage_time[0]-stage_time[2]:
        return survival_probs[2]
    
def getEta(survival_probs,diagnosis_probs,eps=0.01,TDELTA=1,Plot=False):
    a=np.array([s_prob(i-TDELTA,survival_probs) for i in np.arange(eps,10,eps)])
    b=np.array([s_prob(i,survival_probs) for i in np.arange(eps,10,eps)])
    c=np.array([dx_prob(i,diagnosis_probs,survival_probs) for i in np.arange(eps,10,eps)])
    if Plot:
        plt.plot(np.arange(eps,10,eps),a-b)
        plt.plot(np.arange(eps,10,eps),c)
    return np.array([i*j*eps for i,j in zip(a-b,c)]).sum()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="zedstat.zedstat.dx_prob"><code class="name flex">
<span>def <span class="ident">dx_prob</span></span>(<span>t, diagnosis_probs, survival_probs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dx_prob(t,diagnosis_probs,survival_probs):
    stage_time = [getTime(survival_probs[0])-getTime(survival_probs[1]),
                  getTime(survival_probs[1])-getTime(survival_probs[2]),
                  getTime(survival_probs[2])] 

    if t &lt; stage_time[0]-stage_time[1]:
        return diagnosis_probs[0]
    if t &lt; stage_time[0]-stage_time[2]:
        return diagnosis_probs[1]
    if t &gt; stage_time[0]-stage_time[2]:
        return diagnosis_probs[2]</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.genroc"><code class="name flex">
<span>def <span class="ident">genroc</span></span>(<span>df, risk='predicted_risk', target='target', steps=1000, TARGET=[1], outfile=None)</span>
</code></dt>
<dd>
<div class="desc"><p>compute roc curve from raw observation of risk-target information on samples</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>dataframe of raw samples identified as positive or negative with computed risk</dd>
<dt><strong><code>target</code></strong> :&ensp;<code>str</code></dt>
<dd>name of target column</dd>
<dt><strong><code>risk</code></strong> :&ensp;<code>str</code></dt>
<dd>name of risk column</dd>
<dt><strong><code>TARGET</code></strong> :&ensp;<code>list</code></dt>
<dd>list of values of target column that define the positive case, default [1]</dd>
<dt><strong><code>steps</code></strong> :&ensp;<code>int</code></dt>
<dd>steps between max and min of risk value, default 1000</dd>
<dt><strong><code>outfile</code></strong> :&ensp;<code>str</code></dt>
<dd>write datafraem with fpr tpr threshold, default None</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.DataFrame</code></dt>
<dd>roc dataframe</dd>
<dt><code>int</code></dt>
<dd>total number of samples</dd>
<dt><code>int</code></dt>
<dd>total number of positive samples</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def genroc(df,
           risk=&#39;predicted_risk&#39;,
           target=&#39;target&#39;,
           steps=1000,
           TARGET=[1],
           outfile=None):
    &#39;&#39;&#39;
    compute roc curve from raw observation of risk-target information on samples

    Args:
        df (pandas.DataFrame): dataframe of raw samples identified as positive or negative with computed risk
        target (str): name of target column
        risk (str): name of risk column
        TARGET (list): list of values of target column that define the positive case, default [1]
        steps (int): steps between max and min of risk value, default 1000
        outfile (str): write datafraem with fpr tpr threshold, default None

    Returns:
        pandas.DataFrame: roc dataframe
        int: total number of samples
        int: total number of positive samples
    &#39;&#39;&#39;
    threshold={}
    df_=df[[risk,target]].rename(columns={risk:&#39;risk&#39;,target:&#39;target&#39;})
    delta=(df_.risk.max()-df_.risk.min())/steps
    for r in np.arange(df_.risk.min(),df_.risk.max()+delta,delta):
        #print(r)
        fn=df_[(df_.risk&lt;r) &amp; df_.target.isin(TARGET)].index.size
        tp=df_[(df_.risk&gt;=r) &amp; df_.target.isin(TARGET)].index.size
        fp=df_[(df_.risk&gt;=r) &amp; ~df_.target.isin(TARGET)].index.size
        tn=df_[(df_.risk&lt;r) &amp; ~df_.target.isin(TARGET)].index.size
        threshold[r]={&#39;tp&#39;:tp,&#39;fp&#39;:fp,&#39;tn&#39;:tn,&#39;fn&#39;:fn}
        
    xf=pd.DataFrame.from_dict(threshold).transpose()
    xf.index.name=&#39;threshold&#39;
    
    xf=xf.assign(tpr=(xf.tp)/(xf.tp+xf.fn)).assign(fpr=(xf.fp)/(xf.fp+xf.tn))
    xf=xf[[&#39;fpr&#39;,&#39;tpr&#39;]].reset_index()#.set_index(&#39;fpr&#39;)
    
    if outfile is not None:
        xf.to_csv(outfile)
    return xf,df_.index.size,df_[df_.target.isin(TARGET)].index.size    </code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.getEta"><code class="name flex">
<span>def <span class="ident">getEta</span></span>(<span>survival_probs, diagnosis_probs, eps=0.01, TDELTA=1, Plot=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getEta(survival_probs,diagnosis_probs,eps=0.01,TDELTA=1,Plot=False):
    a=np.array([s_prob(i-TDELTA,survival_probs) for i in np.arange(eps,10,eps)])
    b=np.array([s_prob(i,survival_probs) for i in np.arange(eps,10,eps)])
    c=np.array([dx_prob(i,diagnosis_probs,survival_probs) for i in np.arange(eps,10,eps)])
    if Plot:
        plt.plot(np.arange(eps,10,eps),a-b)
        plt.plot(np.arange(eps,10,eps),c)
    return np.array([i*j*eps for i,j in zip(a-b,c)]).sum()</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.getTime"><code class="name flex">
<span>def <span class="ident">getTime</span></span>(<span>s, time_5_year_exp=5, target_survival_exp=0.99)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getTime(s,time_5_year_exp=5,target_survival_exp=.99):
    lambd_exp = -np.log(s) / time_5_year_exp
    return -np.log(target_survival_exp) / lambd_exp</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.pipeline"><code class="name flex">
<span>def <span class="ident">pipeline</span></span>(<span>df, risk='predicted_risk', target='target', steps=1000, TARGET=[1], order=3, alpha=0.05, prevalence=0.002, precision=3, outfile=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pipeline(df,
            risk=&#39;predicted_risk&#39;,
            target=&#39;target&#39;,
            steps=1000,
            TARGET=[1],
            order=3,
            alpha=0.05,
            prevalence=.002,
            precision=3,
            outfile=None):
    rf,total_samples,positive_samples=genroc(df,risk=risk,
                                             target=target,
                                             TARGET=TARGET)
    zt=processRoc(rf,
                  order=order, 
                  total_samples=total_samples,
                  positive_samples=positive_samples,
                  alpha=alpha,
                  prevalence=prevalence)
    
    zt.smooth(STEP=0.001)
    zt.allmeasures(interpolate=True)
    zt.usample(precision=precision)
    zt.getBounds()

    df_=zt.get()
    df_u=zt.df_lim[&#39;U&#39;]
    df_l=zt.df_lim[&#39;L&#39;]

    df_=df_.join(df_u,rsuffix=&#39;_upper&#39;).join(df_l,rsuffix=&#39;_lower&#39;)

    if outfile is not None:
        df_.to_csv(outfile)

    return df_,zt.auc()</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.s_prob"><code class="name flex">
<span>def <span class="ident">s_prob</span></span>(<span>t, survival_probs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def s_prob(t,survival_probs):
    stage_time = [getTime(survival_probs[0])-getTime(survival_probs[1]),
                  getTime(survival_probs[1])-getTime(survival_probs[2]),
                  getTime(survival_probs[2])] 
    
    if t &lt; stage_time[0]-stage_time[1]:
        return survival_probs[0]
    if t &lt; stage_time[0]-stage_time[2]:
        return survival_probs[1]
    if t &gt; stage_time[0]-stage_time[2]:
        return survival_probs[2]</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.score_to_probability"><code class="name flex">
<span>def <span class="ident">score_to_probability</span></span>(<span>scores, df, prevalence, total_samples, positive_samples, alpha=0.05)</span>
</code></dt>
<dd>
<div class="desc"><p>returns score to probability and upper and lower bound fast
and robust, standalone.
implements: Statist. Med. 2007; 26:3258–3273
DOI: 10.1002/sim.2812
Prevalence-dependent diagnostic accuracy measures
Jialiang Li, Jason P. Fine and Nasia Safdar</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def score_to_probability(scores,df,
                  prevalence,
                  total_samples,
                  positive_samples,
                  alpha=0.05):
    &#39;&#39;&#39;
    returns score to probability and upper and lower bound fast 
    and robust, standalone.
    implements: Statist. Med. 2007; 26:3258–3273
    DOI: 10.1002/sim.2812
    Prevalence-dependent diagnostic accuracy measures
    Jialiang Li, Jason P. Fine and Nasia Safdar
    &#39;&#39;&#39;
    from scipy.stats import norm
    z = norm.ppf(1 - alpha / 2)
    se=df.tpr
    sp=1-df.fpr
    var_se = se * (1 - se) / positive_samples
    var_sp = sp * (1 - sp) / (total_samples - positive_samples)
    df[&#39;g1&#39;]= (1 - sp) / se
    sigma_1 = np.sqrt(total_samples * (1 - sp)**2 * var_se / (se**4) + total_samples * var_sp / (se**2))
    df[&#39;ci_g1&#39;] =  z * (sigma_1 / np.sqrt(total_samples))
    df[&#39;ppv&#39;] = se * prevalence / (se * prevalence + (1 - sp) * (1 - prevalence))
    df[&#39;ppv_lower&#39;] = 1/(1+ ((1-prevalence)/prevalence)*(df[&#39;g1&#39;]-df[&#39;ci_g1&#39;]))
    df[&#39;ppv_upper&#39;] = 1/(1+ ((1-prevalence)/prevalence)*(df[&#39;g1&#39;]+df[&#39;ci_g1&#39;]))
    df=df.dropna().drop([&#39;g1&#39;,&#39;ci_g1&#39;],axis=1)
    
    return [df[df.threshold&gt;=score].tail(1)[[&#39;ppv&#39;,&#39;ppv_upper&#39;,&#39;ppv_lower&#39;]].round(2).values[0] for score in scores]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="zedstat.zedstat.processRoc"><code class="flex name class">
<span>class <span class="ident">processRoc</span></span>
<span>(</span><span>df=None, fprcol='fpr', tprcol='tpr', thresholdcol='threshold', prevalence=None, order=2, total_samples=None, positive_samples=None, alpha=0.05)</span>
</code></dt>
<dd>
<div class="desc"><p>process ROC datafile</p>
<p>Initialization</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>dataframe with columns tabulating fpr, tpr, and optionally threshold values</dd>
<dt><strong><code>fprcol</code></strong> :&ensp;<code>str</code></dt>
<dd>string name of fpr column</dd>
<dt><strong><code>tprcol</code></strong> :&ensp;<code>str</code></dt>
<dd>string name of tpr column</dd>
<dt><strong><code>thresholdcol</code></strong> :&ensp;<code>str</code></dt>
<dd>string name of threshold column</dd>
<dt><strong><code>prevalence</code></strong> :&ensp;<code>float</code></dt>
<dd>prevalence of positive cases in population (need not be the data ratio)</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>int</code></dt>
<dd>order of polynomial/spline for smoothing</dd>
<dt><strong><code>total_samples</code></strong> :&ensp;<code>int</code></dt>
<dd>total number of samples in the original data</dd>
<dt>positive samples (int): number of positive cases in the original data</dt>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>significance level e.g. 0.05</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class processRoc(object):
    &#34;&#34;&#34;process ROC datafile&#34;&#34;&#34;

    def __init__(self,
                 df=None,
                 fprcol=&#39;fpr&#39;,
                 tprcol=&#39;tpr&#39;,
                 thresholdcol=&#39;threshold&#39;,
                 prevalence=None,
                 order=2,
                 total_samples=None,
                 positive_samples=None,
                 alpha=0.05):

        &#34;&#34;&#34;Initialization

        Args:
            df (pandas.DataFrame): dataframe with columns tabulating fpr, tpr, and optionally threshold values
            fprcol (str): string name of fpr column
            tprcol (str): string name of tpr column
            thresholdcol (str): string name of threshold column
            prevalence (float): prevalence of positive cases in population (need not be the data ratio)
            order (int): order of polynomial/spline for smoothing
            total_samples (int): total number of samples in the original data
            positive samples (int): number of positive cases in the original data
            alpha (float): significance level e.g. 0.05
        &#34;&#34;&#34;
        
        #print(&#39;local version 1&#39;)
        
        if df.index.name==fprcol:
            self.df=df.copy()
        else:
            if fprcol in df.columns:
                self.df=df.set_index(fprcol).copy()
            else:
                raise(&#39;fpr not in columns or index&#39;)
        self.thresholdcol = thresholdcol
            
        if thresholdcol not in self.df.columns:
            self.thresholdcol=None

        self.df = self.df.sort_values(&#39;fpr&#39;)
            
        self.fprcol = fprcol
        self.tprcol = tprcol
        self.raw_df = self.df.copy()
        self.prevalence = prevalence
        self.order = order
        self.df_lim = {}
        self._auc = {&#39;U&#39;:[],&#39;L&#39;:[]}
        self.total_samples = total_samples
        self.positive_samples = positive_samples
        self.alpha = alpha
        
        self.df=self.df.groupby(self.fprcol).max().reset_index()

        
    def get(self):
        &#39;&#39;&#39;
        return dataframe currently in class

        Returns:
            pandas.DataFrame 
        &#39;&#39;&#39;
        return self.df.copy()
    

    def nominal_auc(self):
        &#39;&#39;&#39;
        calculate nominal auc
        &#39;&#39;&#39;
        from sklearn.metrics import auc
        self._auc[&#39;nominal&#39;]=auc(self.df.index.values,self.df.tpr.values)
        return

    
    def auc(self,
            total_samples=None,
            positive_samples=None,
            alpha=None):
        &#39;&#39;&#39;
        calculate auc with confidence bounds. As default, the arguments are read from class initializtion.

        Args:
            total_samples (int): total number fo samples, default None
            positive_samples (int): number fo positive samples, default None
            alpha (float): significance level, default None

        Returns:
            float: nominal auc
            float: upper bound
            float: lower bound
        
        &#39;&#39;&#39;
        self.nominal_auc()
        self._auc[&#39;U&#39;]=[]
        self._auc[&#39;L&#39;]=[]
        
        self.getBounds(total_samples=total_samples,
                positive_samples=positive_samples,
                alpha=alpha)
        self.__auc_cb2(total_samples=total_samples,
                positive_samples=positive_samples,
                alpha=alpha)
        return self._auc[&#39;nominal&#39;], self._auc[&#39;U&#39;].min(), self._auc[&#39;L&#39;].max()

    
    def __convexify(self):
        &#39;&#39;&#39;
        compute convex hull of the roc curve
        &#39;&#39;&#39;
        #print(self.df)
        from scipy.spatial import ConvexHull
        if self.df.index.name==self.fprcol:
            rf=self.df
        else:
            if self.fprcol in self.df.columns:
                rf=self.df.set_index(self.fprcol)#.drop(&#39;threshold&#39;,axis=1)
            else:
                raise(&#39;fpr not in columns or index&#39;)

        rf = rf.reset_index()
        rf=pd.concat([rf,pd.DataFrame({self.fprcol:0, self.tprcol:0},index=[0])])
        rf=pd.concat([rf,pd.DataFrame({self.fprcol:1, self.tprcol:0},index=[0])])
        rf=pd.concat([rf,pd.DataFrame({self.fprcol:1, self.tprcol:1},index=[0])])
        
        rf=rf.drop_duplicates()
        rf=rf.sort_values(self.fprcol)
        rf=rf.sort_values(self.tprcol)

        pts=rf[[self.fprcol,self.tprcol]].values

        #print(pts)
        
        if len(pts)&lt;3:
            rf_=rf.copy()
            rf_.columns=[self.tprcol,self.fprcol]
            rf_=rf_.sort_values(self.fprcol)
            rf_=rf_.sort_values(self.tprcol)
            self.df=rf_.set_index(self.fprcol).copy()
            return #self.df
        
        hull = ConvexHull(pts)
        rf_=pd.DataFrame(pts[hull.vertices, 0], pts[hull.vertices, 1]).reset_index()
        rf_.columns=[self.tprcol,self.fprcol]
        rf_ = rf_.set_index(self.fprcol)
        
        rf_ = rf_.drop(1.0).sort_index()
        rf_.loc[1.0]=1.0
        
        self.df=rf_.copy()
        return 


    def smooth(self,
               STEP=0.0001,
               interpolate=True,
               convexify=True):
        &#39;&#39;&#39;
        smooth roc curves and update processRoc.df which is accessible using processRoc.get()

        Args:
            STEP (float): smooting step, default 0.0001
            interpolate (bool): if True, interpolate missing values, default True
            convexify (bool): if True, replace ROC with convex hull, default True
        &#39;&#39;&#39;
        self.df=self.raw_df.copy()
        VAR=self.fprcol
        df_=self.df.reset_index()
        DF=pd.concat([pd.DataFrame(
            df_[df_[VAR].between(i,i+STEP)].max()).transpose()
                      for i in np.arange(0,1,STEP)]).set_index(VAR)
        DF=DF.dropna()
        DF.loc[0]=pd.Series([],dtype=float) 
        DF.loc[1]=pd.Series([],dtype=float) 
        DF.loc[0,&#39;tpr&#39;]=0
        DF.loc[1,&#39;tpr&#39;]=1
        
        DF=DF.sort_index()
        if interpolate:
            DF=DF.interpolate(limit_direction=&#39;both&#39;,method=&#39;spline&#39;,order=self.order)
            DF[DF &lt; 0] = 0
            self.df=DF
        if convexify:
            self.__convexify()
        return 

    
    def allmeasures(self,prevalence=None,interpolate=False):
        &#39;&#39;&#39;
        compute accuracy, PPV, NPV, positive and negative likelihood ratios, and update processRoc.df, which can be accessed using processRoc.get()

        Args:
            prevalence (float): prevalence od positive cases in population
            interpolate (bool): if True interpolate missing values, default False
        &#39;&#39;&#39;
        if prevalence is not None:
            p=prevalence
            self.prevalence=p
        else:
            p=self.prevalence
        if p is None:
            raise(&#39;prevalence undefined&#39;)
        df__=self.df.copy()
        if self.fprcol == df__.index.name:
            df__=df__.reset_index()
            df__[&#39;ppv&#39;]=1/(1+((df__.fpr/df__.tpr)*((1/p)-1)))
            df__[&#39;acc&#39;]=p*df__.tpr + (1-p)*(1-df__.fpr)
            df__[&#39;npv&#39;]=1/(1+((1-df__.tpr)/(1-df__.fpr))*(1/((1/p)-1)))
            df__[&#39;LR+&#39;]=(df__.tpr)/(df__.fpr)
            df__[&#39;LR-&#39;]=(1-df__.tpr)/(1-df__.fpr)
        else:
            assert(&#39;set fpr as index&#39;)
            
            
        df__=df__.set_index(self.fprcol)

        #display(df__)
        df__=df__.replace(np.inf,np.nan)
        #display(df__)


        
        if interpolate:
            try:
                df__=df__.interpolate(limit_direction=&#39;both&#39;,method=&#39;spline&#39;,order=self.order)
            except:
                print(&#39;interpolation failed&#39;)

 
        #display(df__)
        
        if self.thresholdcol is not None:
            if self.thresholdcol not in df__.columns:
                df__=df__.join(self.raw_df[self.thresholdcol])
        self.df=df__
        self.__correctPPV()
        self.df[self.df &lt; 0] = 0


        self.df=self.df.reset_index().groupby(&#39;fpr&#39;).max()
        self.df.ppv=UnivariateSpline(self.df.index.values,self.df.ppv.values,k=1,s=None)(self.df.index.values)
        self.df[self.df &lt; 0] = 0

        #display(self.df)
        
        return #self.df


    def __correctPPV(self,df=None):
        &#39;&#39;&#39;
        make ppv monotonic
        &#39;&#39;&#39;
        if &#39;ppv&#39; not in self.df.columns:
            return

        if df is None:
            df__=self.df
        else:
            df__=df.copy()
            
        
        #df__.loc[0].ppv=1.0
        #df__.loc[1].ppv=0.0
        arr=df__.ppv.values
        a_=[]
        for i in np.arange(len(arr)-1):
            if arr[i+1]&gt;arr[i]:
                a_.append(1.05*arr[i+1])
            else:
                a_.append(arr[i])
        a_.append(arr[-1])

        
        df__.ppv=a_
        #df__.loc[0].ppv=1.0
        #df__.loc[1].ppv=0.0
        
        
        return df__


    def scoretoprobability(self, score, regen=True, **kwargs):
        &#39;&#39;&#39;
        Map computed score to probability of sample being in the positive class.
        This is simply the PPV corresponding to the threshold which equals the score.
        Now supports both single scores and lists/numpy arrays of scores.

        Args:
            score (float or list or numpy.ndarray): computed score(s)
            regen (bool): if True, regenerate roc curve
            kwargs (dict): values passed for regeneration of smoothed roc

        Return:
            float or numpy.ndarray representing probability of being in positive cohort
        &#39;&#39;&#39;

        if score is None:
            return None

        if regen:
            STEP = 0.01
            precision = 3
            interpolate = True

            STEP = kwargs.get(&#39;STEP&#39;, STEP)
            precision = kwargs.get(&#39;precision&#39;, precision)
            interpolate = kwargs.get(&#39;interpolate&#39;, interpolate)

            self.smooth(STEP=STEP)
            self.allmeasures(interpolate=interpolate)
            self.usample(precision=precision)

        df = self.get()
        if &#39;threshold&#39; not in df.columns:
            raise ValueError(&#39;Threshold not in columns or index&#39;)
        if &#39;ppv&#39; not in df.columns:
            raise ValueError(&#39;PPV not in columns or index&#39;)

        def compute_val(score):
            if score is None:
                return None
            if score &gt; df.threshold.max():
                val = df.ppv.values.max()
            else:
                val = df[df.threshold &gt; score].ppv.tail(1).values[0]
            return (val - df.ppv.values.min()) / (df.ppv.values.max() - df.ppv.values.min())

        if isinstance(score, (list, np.ndarray)):
            return np.array([compute_val(s) for s in score])
        else:
            return compute_val(score)

    
    def usample(self,
                df=None,
                precision=3):
        &#39;&#39;&#39;
        make performance measures estimated at regular intervals of false positive rate

        Args:
            df (pandas.DataFrame): dataframe woth performance values, fpr as index. default: None, when the dataframe entered at initialization is used
            precision (int): number of digits after decismal point used to sample fpr range
        
        Returns:
            pandas.DataFrame: uniformly sampled performance dataframe
        &#39;&#39;&#39;
        step=10**(-precision)
        fpr=[np.round(x,precision) for x in np.arange(0,1+step,step)]
        if df is None:        
            fpr_=[x for x in fpr if x not in self.df.index]
        else:
            fpr_=[x for x in fpr if x not in df.index]

        if df is None:
            df___=self.df.copy()
        else:
            df___=df.copy()
            
        for x in fpr_:
            df___.loc[x]=pd.Series([],dtype=float) 
        df___=df___.sort_index().interpolate()
        
        df___=df___.loc[fpr]        
        if df is None:
            self.df=df___

        return df___


    def __getDelta(self,
                 total_samples=None,
                 positive_samples=None,
                 alpha=None):
        &#39;&#39;&#39;
        confidence bounds on specificity and sensitivity using Wald-type approach
        &#39;&#39;&#39;
        if total_samples is None:
            total_samples=self.total_samples
        if positive_samples is None:
            positive_samples = self.positive_samples
        if alpha is None:
            alpha=self.alpha
            
        n=total_samples
        n_pos=positive_samples
        
        if self.fprcol not in self.df.columns:
            if self.fprcol != self.df.index.name:
                return
        if self.tprcol not in self.df.columns:
            return
        
        import scipy.stats as stats
        z=stats. norm. ppf(1 - (alpha/2))
        delta_=pd.DataFrame()
        df_=self.df.copy()
        if self.fprcol == df_.index.name:
            df_=df_.reset_index()
            delta_[&#39;fprdel&#39;]=z*np.sqrt((df_.fpr*(1-df_.fpr))/n)
            delta_[&#39;tprdel&#39;]=z*np.sqrt((df_.tpr*(1-df_.tpr))/n_pos)
            self.delta_=delta_
        return 

    
    def getBounds(self,
                  total_samples=None,
                  positive_samples=None,
                  alpha=None,
                  prevalence=None):
        &#39;&#39;&#39;
        compute confidence bounds on performance measures

        Args:
            total_samples (int): total number fo samples, default None
            positive_samples (int): number fo positive samples, default None
            alpha (float): significance level, default None
            prevalence (float): prevalence of positive cases in population, default None

        &#39;&#39;&#39;
        self.__getDelta(total_samples=total_samples,
                 positive_samples=positive_samples,
                      alpha=alpha)

        if prevalence is None:
            p=self.prevalence
        else:
            p=prevalence
        
        if p is None:
            raise(&#39;prevalence undefined&#39;)

        for direction in [&#39;U&#39;,&#39;L&#39;]:
            df__=self.df.copy().reset_index()

            if direction==&#39;U&#39;:
                df__.tpr=df__.tpr+self.delta_.tprdel
                #df__.fpr=df__.fpr-self.delta_.fprdel
            else:
                df__.tpr=df__.tpr-self.delta_.tprdel
                #df__.fpr=df__.fpr+self.delta_.fprdel
                
            df__[&#39;ppv&#39;]=1/(1+((df__.fpr/df__.tpr)*((1/p)-1)))
            df__[&#39;acc&#39;]=p*df__.tpr + (1-p)*(1-df__.fpr)
            df__[&#39;npv&#39;]=1/(1+((1-df__.tpr)/(1-df__.fpr))*(1/((1/p)-1)))
            df__[&#39;LR+&#39;]=(df__.tpr)/(df__.fpr)
            df__[&#39;LR-&#39;]=(1-df__.tpr)/(1-df__.fpr)

            df__=df__.replace(np.inf,np.nan)

            
            df__=df__.interpolate(limit_direction=&#39;both&#39;,method=&#39;spline&#39;,
                                  order=self.order).set_index(self.fprcol)
            df__[df__ &lt; 0] = 0

            self.df_lim[direction]=self.__correctPPV(df__)
            
            if direction==&#39;U&#39;:
                self._auc[direction]=np.array([np.append(self._auc[direction],
                                                auc(df__.index.values,
                                                    df__.tpr.values)).min()])
            if direction==&#39;L&#39;:
                self._auc[direction]=np.array([np.append(self._auc[direction],
                                                auc(df__.index.values,
                                                    df__.tpr.values)).max()])


            # adjust datframe to cneter of upper and lowwr bounds    
        #self.df=(self.df_lim[&#39;U&#39;]+ self.df_lim[&#39;L&#39;] )/2
        #self.__correctvalues()
        return 

    def __correctvalues(self):
        #ppv
        if &#39;ppv&#39; in self.df.columns:
            self.df.ppv[self.df.ppv&gt;1]=1.0
        if &#39;npv&#39; in self.df.columns:
            self.df.npv[self.df.npv&gt;1]=1.0
        if &#39;LR-&#39; in self.df.columns:
            self.df[&#39;LR-&#39;][self.df[&#39;LR-&#39;]&gt;1]=1.0
            

    def __auc_cb2(self,
                total_samples=None,
                positive_samples=None,
                alpha=None):
        &#39;&#39;&#39;
        compute auc confidence bounds using Danzig bounds

        Args:
            total_samples (int): total number fo samples, default None
            positive_samples (int): number fo positive samples, default None
            alpha (float): significance level, default None
        &#39;&#39;&#39;
        if total_samples is None:
            total_samples=self.total_samples
        if positive_samples is None:
            positive_samples = self.positive_samples
        if alpha is None:
            alpha=self.alpha

        n=total_samples
        n_pos=positive_samples


        if &#39;nominal&#39; not in self._auc.keys():
            assert(&#39;calculate nominal auc first&#39;)
            
        import scipy.stats as stats
        auc=self._auc[&#39;nominal&#39;]
        z=stats. norm. ppf(1 - (alpha/2))

        eta=1+(n_pos/(z*z))
        b=(auc-.5)/eta
        auc_U=auc+b+ (1/eta)*np.sqrt((auc-.5)**2 + (auc*(1-auc)*eta))
        auc_L=auc+b- (1/eta)*np.sqrt((auc-.5)**2 + (auc*(1-auc)*eta))

        self._auc[&#39;L&#39;]=np.array([np.append(self._auc[&#39;L&#39;],auc_L).max()])
        self._auc[&#39;U&#39;]=np.array([np.append(self._auc[&#39;U&#39;],auc_U).min()])

        return

    
    def operating_zone(self,
                       n=1,
                       LRplus=10,
                       LRminus=0.6):
        &#39;&#39;&#39;
        compute the end points of the operating zone, 
        one for maximizing precions, and one for maximizing sensitivity

        Args:
            n (int): number of operting points per condition returned, default 1
            LRplus (float): lower bound on positive likelihood ratio, default 10.0
            LRminus (float): upper bound on negative likelihood ratio, default 0.6

        &#39;&#39;&#39;
        wf=self.df.copy()
        
        opf=pd.concat([wf[(wf[&#39;LR+&#39;]&gt;LRplus)
                          &amp; (wf[&#39;LR-&#39;]&lt;LRminus) ]\
                       .sort_values(&#39;ppv&#39;,ascending=False).head(n),
                       wf[(wf[&#39;LR+&#39;]&gt;LRplus)
                          &amp; (wf[&#39;LR-&#39;]&lt;LRminus) ]\
                       .sort_values(&#39;tpr&#39;,ascending=False).head(n)])

        if opf.empty:
            self._operating_zone=opf.copy()
            return #self._operating_zone.copy()
        self._operating_zone=opf.reset_index()
        self._operating_zone.index=[&#39;high precision&#39;]*n + [&#39;high sensitivity&#39;]*n
        return #self._operating_zone.copy()

    
    def samplesize(self,
                   delta_auc=0.1,
                   target_auc=None,
                   alpha=None):
        &#39;&#39;&#39;
        estimate sample size for atataing auc bound under given significance level

        Args:
            delta_auc (float): maximum perturbation from estimated auc, default 0.1
            target_auc (float): if None, using estimate current nominal auc
            alpha (float): significanec level. If None use processRoc.alpha

        Returns:
            float: minimum sample size
        &#39;&#39;&#39;
        if alpha is None:
            alpha=self.alpha

        if target_auc is None:
            if &#39;nominal&#39; not in self._auc.keys():
                self.auc()
            target_auc=self._auc[&#39;nominal&#39;]
            
        import scipy.stats as stats
        z=stats. norm. ppf(1 - (alpha/2))
        required_npos = (z*z)*target_auc*(1-target_auc)/(delta_auc*delta_auc)

        return required_npos

    def pvalue(self,
               delta_auc=0.1,
               twosided=True):
        &#39;&#39;&#39;
        compute p-value for given auc bounds

        Args:
            delta_auc (float): maximum perturbation from estimated auc, default 0.1
            twosided (bool): one sided or twosided confidence bounds

        Returns:
            float: pvalue for the null hypothesis that estimated nominal auc is lower by more than delta_auc
        &#39;&#39;&#39;
        if &#39;nominal&#39; not in self._auc.keys():
            self.auc()
        auc=self._auc[&#39;nominal&#39;]
            
        import scipy.stats as stats
        z=np.sqrt(self.positive_samples/(auc*(1-auc)/(delta_auc*delta_auc)) )
        pvalue=stats.norm.sf(abs(z))

        if twosided:
            pvalue=2*pvalue
        return pvalue
    
    
    def interpret(self,
                  fpr=0.01,
                  number_of_positives=10,
                  five_yr_survival=None,
                  cancer=True,
                  TDELTA=1,
                  diagnosis_probs=None,
                  survival_probs=None,
                  factor=1):
        &#39;&#39;&#39;
        generate simple interpretation of inferred model, based on a number of positive cases

        Args:
            fpr (float): the false psotive rate or 1-specificity of the operating point
            number_of_positives (int): interpret assuming this many positive cases, default 10
            five_yr_survival (float): fraction not experiencing severe event after 5 years (default: None)
            factor (float): fraction of TP who avert the severe outcome due to correct screen
        &#39;&#39;&#39;
        wf=self.df.copy()
                
        wf.loc[fpr]=pd.Series([],dtype=float)
        wf=wf.sort_index().interpolate(method=&#39;spline&#39;,order=self.order,limit_direction=&#39;both&#39;)
        
        row=wf.loc[fpr]

#        POS=number_of_positives
#        TP=POS*row.tpr
#        FP = TP*((1/row.ppv) -1)
#        NEG=FP/fpr
#        TOTALFLAGS=TP+FP
#        FN=POS-TP
#        TN=POS/self.prevalence

        #factor=0.21*(0.95-0.69) + 0.08*(0.95-0.17)
        #factor=0.33*(0.95-0.17)

        POS=number_of_positives
        NEG=POS*(1-self.prevalence)*(1/self.prevalence)
        TP=POS*row.tpr
        TOTALFLAGS=TP/row.ppv
        FP=TOTALFLAGS-TP
        FN=POS-TP
        TN=NEG-FP
        if five_yr_survival is not None:
            NNS=TOTALFLAGS/(TP*factor*(1- five_yr_survival))
        else:
            if cancer:
                eta=getEta(survival_probs,diagnosis_probs,TDELTA=TDELTA)
                PPV= (TP/(POS+NEG)) * self.prevalence / ((TP/(POS)) * self.prevalence + (FP/NEG) * (1 - self.prevalence)) 
                NNS=1/(eta*PPV)
            else: 
                NNS=np.nan

            
        resdf=pd.DataFrame.from_dict({&#34;POS&#34;:np.round(POS),&#34;TP&#34;:np.round(TP),
                                      &#34;FP&#34;:np.round(FP),&#34;NEG&#34;:np.round(NEG),
                                      &#34;FLAGS&#34;:np.round(TOTALFLAGS),&#34;FN&#34;:np.round(FN),
                                      &#34;TN&#34;:np.round(TN),
                                      &#34;NNS&#34;:np.round(NNS),
                                      &#34;FLAGGED_FRACTION&#34;:np.round(TOTALFLAGS/(POS+NEG),
                                                                  2)},orient=&#39;index&#39;,columns=[&#39;estimates&#39;])
        
        rf=pd.DataFrame({&#39;pos&#39;:np.round(POS),
                      &#39;flags&#39;:int(np.round(TOTALFLAGS)),
                      &#39;tp&#39;:int(np.round(TP)),
                      &#39;fp&#39;:int(np.round(FP)),
                      &#39;fn&#39;:int(np.round(FN)),
                      &#39;tn&#39;:int(np.round(TN))},index=[&#39;numbers&#39;])

        pos=rf.pos.values[0]
        flags=rf[&#39;flags&#39;].values[0]
        fp=rf[&#39;fp&#39;].values[0]
        tp=rf[&#39;tp&#39;].values[0]
        fn=rf[&#39;fn&#39;].values[0]

        txt=[f&#34;For every {pos} positive instances&#34;,
             f&#34;we raise {flags} flags,&#34;,
             f&#34;out of which {tp} are true positives&#34;,
             f&#34;{fp} are false alarms&#34;,
             f&#34;{fn} cases are missed&#34;]
        if five_yr_survival is not None:
            txt.append(f&#34;Number needed to screen is {NNS}&#34;)
        if cancer:
            txt.append(f&#34;Number needed to screen is {NNS}&#34;)
        
            

        return rf,txt,resdf</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="zedstat.zedstat.processRoc.allmeasures"><code class="name flex">
<span>def <span class="ident">allmeasures</span></span>(<span>self, prevalence=None, interpolate=False)</span>
</code></dt>
<dd>
<div class="desc"><p>compute accuracy, PPV, NPV, positive and negative likelihood ratios, and update processRoc.df, which can be accessed using processRoc.get()</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>prevalence</code></strong> :&ensp;<code>float</code></dt>
<dd>prevalence od positive cases in population</dd>
<dt><strong><code>interpolate</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True interpolate missing values, default False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def allmeasures(self,prevalence=None,interpolate=False):
    &#39;&#39;&#39;
    compute accuracy, PPV, NPV, positive and negative likelihood ratios, and update processRoc.df, which can be accessed using processRoc.get()

    Args:
        prevalence (float): prevalence od positive cases in population
        interpolate (bool): if True interpolate missing values, default False
    &#39;&#39;&#39;
    if prevalence is not None:
        p=prevalence
        self.prevalence=p
    else:
        p=self.prevalence
    if p is None:
        raise(&#39;prevalence undefined&#39;)
    df__=self.df.copy()
    if self.fprcol == df__.index.name:
        df__=df__.reset_index()
        df__[&#39;ppv&#39;]=1/(1+((df__.fpr/df__.tpr)*((1/p)-1)))
        df__[&#39;acc&#39;]=p*df__.tpr + (1-p)*(1-df__.fpr)
        df__[&#39;npv&#39;]=1/(1+((1-df__.tpr)/(1-df__.fpr))*(1/((1/p)-1)))
        df__[&#39;LR+&#39;]=(df__.tpr)/(df__.fpr)
        df__[&#39;LR-&#39;]=(1-df__.tpr)/(1-df__.fpr)
    else:
        assert(&#39;set fpr as index&#39;)
        
        
    df__=df__.set_index(self.fprcol)

    #display(df__)
    df__=df__.replace(np.inf,np.nan)
    #display(df__)


    
    if interpolate:
        try:
            df__=df__.interpolate(limit_direction=&#39;both&#39;,method=&#39;spline&#39;,order=self.order)
        except:
            print(&#39;interpolation failed&#39;)


    #display(df__)
    
    if self.thresholdcol is not None:
        if self.thresholdcol not in df__.columns:
            df__=df__.join(self.raw_df[self.thresholdcol])
    self.df=df__
    self.__correctPPV()
    self.df[self.df &lt; 0] = 0


    self.df=self.df.reset_index().groupby(&#39;fpr&#39;).max()
    self.df.ppv=UnivariateSpline(self.df.index.values,self.df.ppv.values,k=1,s=None)(self.df.index.values)
    self.df[self.df &lt; 0] = 0

    #display(self.df)
    
    return #self.df</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.processRoc.auc"><code class="name flex">
<span>def <span class="ident">auc</span></span>(<span>self, total_samples=None, positive_samples=None, alpha=None)</span>
</code></dt>
<dd>
<div class="desc"><p>calculate auc with confidence bounds. As default, the arguments are read from class initializtion.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>total_samples</code></strong> :&ensp;<code>int</code></dt>
<dd>total number fo samples, default None</dd>
<dt><strong><code>positive_samples</code></strong> :&ensp;<code>int</code></dt>
<dd>number fo positive samples, default None</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>significance level, default None</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>nominal auc</dd>
<dt><code>float</code></dt>
<dd>upper bound</dd>
<dt><code>float</code></dt>
<dd>lower bound</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def auc(self,
        total_samples=None,
        positive_samples=None,
        alpha=None):
    &#39;&#39;&#39;
    calculate auc with confidence bounds. As default, the arguments are read from class initializtion.

    Args:
        total_samples (int): total number fo samples, default None
        positive_samples (int): number fo positive samples, default None
        alpha (float): significance level, default None

    Returns:
        float: nominal auc
        float: upper bound
        float: lower bound
    
    &#39;&#39;&#39;
    self.nominal_auc()
    self._auc[&#39;U&#39;]=[]
    self._auc[&#39;L&#39;]=[]
    
    self.getBounds(total_samples=total_samples,
            positive_samples=positive_samples,
            alpha=alpha)
    self.__auc_cb2(total_samples=total_samples,
            positive_samples=positive_samples,
            alpha=alpha)
    return self._auc[&#39;nominal&#39;], self._auc[&#39;U&#39;].min(), self._auc[&#39;L&#39;].max()</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.processRoc.get"><code class="name flex">
<span>def <span class="ident">get</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>return dataframe currently in class</p>
<h2 id="returns">Returns</h2>
<p>pandas.DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get(self):
    &#39;&#39;&#39;
    return dataframe currently in class

    Returns:
        pandas.DataFrame 
    &#39;&#39;&#39;
    return self.df.copy()</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.processRoc.getBounds"><code class="name flex">
<span>def <span class="ident">getBounds</span></span>(<span>self, total_samples=None, positive_samples=None, alpha=None, prevalence=None)</span>
</code></dt>
<dd>
<div class="desc"><p>compute confidence bounds on performance measures</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>total_samples</code></strong> :&ensp;<code>int</code></dt>
<dd>total number fo samples, default None</dd>
<dt><strong><code>positive_samples</code></strong> :&ensp;<code>int</code></dt>
<dd>number fo positive samples, default None</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>significance level, default None</dd>
<dt><strong><code>prevalence</code></strong> :&ensp;<code>float</code></dt>
<dd>prevalence of positive cases in population, default None</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getBounds(self,
              total_samples=None,
              positive_samples=None,
              alpha=None,
              prevalence=None):
    &#39;&#39;&#39;
    compute confidence bounds on performance measures

    Args:
        total_samples (int): total number fo samples, default None
        positive_samples (int): number fo positive samples, default None
        alpha (float): significance level, default None
        prevalence (float): prevalence of positive cases in population, default None

    &#39;&#39;&#39;
    self.__getDelta(total_samples=total_samples,
             positive_samples=positive_samples,
                  alpha=alpha)

    if prevalence is None:
        p=self.prevalence
    else:
        p=prevalence
    
    if p is None:
        raise(&#39;prevalence undefined&#39;)

    for direction in [&#39;U&#39;,&#39;L&#39;]:
        df__=self.df.copy().reset_index()

        if direction==&#39;U&#39;:
            df__.tpr=df__.tpr+self.delta_.tprdel
            #df__.fpr=df__.fpr-self.delta_.fprdel
        else:
            df__.tpr=df__.tpr-self.delta_.tprdel
            #df__.fpr=df__.fpr+self.delta_.fprdel
            
        df__[&#39;ppv&#39;]=1/(1+((df__.fpr/df__.tpr)*((1/p)-1)))
        df__[&#39;acc&#39;]=p*df__.tpr + (1-p)*(1-df__.fpr)
        df__[&#39;npv&#39;]=1/(1+((1-df__.tpr)/(1-df__.fpr))*(1/((1/p)-1)))
        df__[&#39;LR+&#39;]=(df__.tpr)/(df__.fpr)
        df__[&#39;LR-&#39;]=(1-df__.tpr)/(1-df__.fpr)

        df__=df__.replace(np.inf,np.nan)

        
        df__=df__.interpolate(limit_direction=&#39;both&#39;,method=&#39;spline&#39;,
                              order=self.order).set_index(self.fprcol)
        df__[df__ &lt; 0] = 0

        self.df_lim[direction]=self.__correctPPV(df__)
        
        if direction==&#39;U&#39;:
            self._auc[direction]=np.array([np.append(self._auc[direction],
                                            auc(df__.index.values,
                                                df__.tpr.values)).min()])
        if direction==&#39;L&#39;:
            self._auc[direction]=np.array([np.append(self._auc[direction],
                                            auc(df__.index.values,
                                                df__.tpr.values)).max()])


        # adjust datframe to cneter of upper and lowwr bounds    
    #self.df=(self.df_lim[&#39;U&#39;]+ self.df_lim[&#39;L&#39;] )/2
    #self.__correctvalues()
    return </code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.processRoc.interpret"><code class="name flex">
<span>def <span class="ident">interpret</span></span>(<span>self, fpr=0.01, number_of_positives=10, five_yr_survival=None, cancer=True, TDELTA=1, diagnosis_probs=None, survival_probs=None, factor=1)</span>
</code></dt>
<dd>
<div class="desc"><p>generate simple interpretation of inferred model, based on a number of positive cases</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fpr</code></strong> :&ensp;<code>float</code></dt>
<dd>the false psotive rate or 1-specificity of the operating point</dd>
<dt><strong><code>number_of_positives</code></strong> :&ensp;<code>int</code></dt>
<dd>interpret assuming this many positive cases, default 10</dd>
<dt><strong><code>five_yr_survival</code></strong> :&ensp;<code>float</code></dt>
<dd>fraction not experiencing severe event after 5 years (default: None)</dd>
<dt><strong><code>factor</code></strong> :&ensp;<code>float</code></dt>
<dd>fraction of TP who avert the severe outcome due to correct screen</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def interpret(self,
                  fpr=0.01,
                  number_of_positives=10,
                  five_yr_survival=None,
                  cancer=True,
                  TDELTA=1,
                  diagnosis_probs=None,
                  survival_probs=None,
                  factor=1):
        &#39;&#39;&#39;
        generate simple interpretation of inferred model, based on a number of positive cases

        Args:
            fpr (float): the false psotive rate or 1-specificity of the operating point
            number_of_positives (int): interpret assuming this many positive cases, default 10
            five_yr_survival (float): fraction not experiencing severe event after 5 years (default: None)
            factor (float): fraction of TP who avert the severe outcome due to correct screen
        &#39;&#39;&#39;
        wf=self.df.copy()
                
        wf.loc[fpr]=pd.Series([],dtype=float)
        wf=wf.sort_index().interpolate(method=&#39;spline&#39;,order=self.order,limit_direction=&#39;both&#39;)
        
        row=wf.loc[fpr]

#        POS=number_of_positives
#        TP=POS*row.tpr
#        FP = TP*((1/row.ppv) -1)
#        NEG=FP/fpr
#        TOTALFLAGS=TP+FP
#        FN=POS-TP
#        TN=POS/self.prevalence

        #factor=0.21*(0.95-0.69) + 0.08*(0.95-0.17)
        #factor=0.33*(0.95-0.17)

        POS=number_of_positives
        NEG=POS*(1-self.prevalence)*(1/self.prevalence)
        TP=POS*row.tpr
        TOTALFLAGS=TP/row.ppv
        FP=TOTALFLAGS-TP
        FN=POS-TP
        TN=NEG-FP
        if five_yr_survival is not None:
            NNS=TOTALFLAGS/(TP*factor*(1- five_yr_survival))
        else:
            if cancer:
                eta=getEta(survival_probs,diagnosis_probs,TDELTA=TDELTA)
                PPV= (TP/(POS+NEG)) * self.prevalence / ((TP/(POS)) * self.prevalence + (FP/NEG) * (1 - self.prevalence)) 
                NNS=1/(eta*PPV)
            else: 
                NNS=np.nan

            
        resdf=pd.DataFrame.from_dict({&#34;POS&#34;:np.round(POS),&#34;TP&#34;:np.round(TP),
                                      &#34;FP&#34;:np.round(FP),&#34;NEG&#34;:np.round(NEG),
                                      &#34;FLAGS&#34;:np.round(TOTALFLAGS),&#34;FN&#34;:np.round(FN),
                                      &#34;TN&#34;:np.round(TN),
                                      &#34;NNS&#34;:np.round(NNS),
                                      &#34;FLAGGED_FRACTION&#34;:np.round(TOTALFLAGS/(POS+NEG),
                                                                  2)},orient=&#39;index&#39;,columns=[&#39;estimates&#39;])
        
        rf=pd.DataFrame({&#39;pos&#39;:np.round(POS),
                      &#39;flags&#39;:int(np.round(TOTALFLAGS)),
                      &#39;tp&#39;:int(np.round(TP)),
                      &#39;fp&#39;:int(np.round(FP)),
                      &#39;fn&#39;:int(np.round(FN)),
                      &#39;tn&#39;:int(np.round(TN))},index=[&#39;numbers&#39;])

        pos=rf.pos.values[0]
        flags=rf[&#39;flags&#39;].values[0]
        fp=rf[&#39;fp&#39;].values[0]
        tp=rf[&#39;tp&#39;].values[0]
        fn=rf[&#39;fn&#39;].values[0]

        txt=[f&#34;For every {pos} positive instances&#34;,
             f&#34;we raise {flags} flags,&#34;,
             f&#34;out of which {tp} are true positives&#34;,
             f&#34;{fp} are false alarms&#34;,
             f&#34;{fn} cases are missed&#34;]
        if five_yr_survival is not None:
            txt.append(f&#34;Number needed to screen is {NNS}&#34;)
        if cancer:
            txt.append(f&#34;Number needed to screen is {NNS}&#34;)
        
            

        return rf,txt,resdf</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.processRoc.nominal_auc"><code class="name flex">
<span>def <span class="ident">nominal_auc</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>calculate nominal auc</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nominal_auc(self):
    &#39;&#39;&#39;
    calculate nominal auc
    &#39;&#39;&#39;
    from sklearn.metrics import auc
    self._auc[&#39;nominal&#39;]=auc(self.df.index.values,self.df.tpr.values)
    return</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.processRoc.operating_zone"><code class="name flex">
<span>def <span class="ident">operating_zone</span></span>(<span>self, n=1, LRplus=10, LRminus=0.6)</span>
</code></dt>
<dd>
<div class="desc"><p>compute the end points of the operating zone,
one for maximizing precions, and one for maximizing sensitivity</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>number of operting points per condition returned, default 1</dd>
<dt><strong><code>LRplus</code></strong> :&ensp;<code>float</code></dt>
<dd>lower bound on positive likelihood ratio, default 10.0</dd>
<dt><strong><code>LRminus</code></strong> :&ensp;<code>float</code></dt>
<dd>upper bound on negative likelihood ratio, default 0.6</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def operating_zone(self,
                   n=1,
                   LRplus=10,
                   LRminus=0.6):
    &#39;&#39;&#39;
    compute the end points of the operating zone, 
    one for maximizing precions, and one for maximizing sensitivity

    Args:
        n (int): number of operting points per condition returned, default 1
        LRplus (float): lower bound on positive likelihood ratio, default 10.0
        LRminus (float): upper bound on negative likelihood ratio, default 0.6

    &#39;&#39;&#39;
    wf=self.df.copy()
    
    opf=pd.concat([wf[(wf[&#39;LR+&#39;]&gt;LRplus)
                      &amp; (wf[&#39;LR-&#39;]&lt;LRminus) ]\
                   .sort_values(&#39;ppv&#39;,ascending=False).head(n),
                   wf[(wf[&#39;LR+&#39;]&gt;LRplus)
                      &amp; (wf[&#39;LR-&#39;]&lt;LRminus) ]\
                   .sort_values(&#39;tpr&#39;,ascending=False).head(n)])

    if opf.empty:
        self._operating_zone=opf.copy()
        return #self._operating_zone.copy()
    self._operating_zone=opf.reset_index()
    self._operating_zone.index=[&#39;high precision&#39;]*n + [&#39;high sensitivity&#39;]*n
    return #self._operating_zone.copy()</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.processRoc.pvalue"><code class="name flex">
<span>def <span class="ident">pvalue</span></span>(<span>self, delta_auc=0.1, twosided=True)</span>
</code></dt>
<dd>
<div class="desc"><p>compute p-value for given auc bounds</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>delta_auc</code></strong> :&ensp;<code>float</code></dt>
<dd>maximum perturbation from estimated auc, default 0.1</dd>
<dt><strong><code>twosided</code></strong> :&ensp;<code>bool</code></dt>
<dd>one sided or twosided confidence bounds</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>pvalue for the null hypothesis that estimated nominal auc is lower by more than delta_auc</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pvalue(self,
           delta_auc=0.1,
           twosided=True):
    &#39;&#39;&#39;
    compute p-value for given auc bounds

    Args:
        delta_auc (float): maximum perturbation from estimated auc, default 0.1
        twosided (bool): one sided or twosided confidence bounds

    Returns:
        float: pvalue for the null hypothesis that estimated nominal auc is lower by more than delta_auc
    &#39;&#39;&#39;
    if &#39;nominal&#39; not in self._auc.keys():
        self.auc()
    auc=self._auc[&#39;nominal&#39;]
        
    import scipy.stats as stats
    z=np.sqrt(self.positive_samples/(auc*(1-auc)/(delta_auc*delta_auc)) )
    pvalue=stats.norm.sf(abs(z))

    if twosided:
        pvalue=2*pvalue
    return pvalue</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.processRoc.samplesize"><code class="name flex">
<span>def <span class="ident">samplesize</span></span>(<span>self, delta_auc=0.1, target_auc=None, alpha=None)</span>
</code></dt>
<dd>
<div class="desc"><p>estimate sample size for atataing auc bound under given significance level</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>delta_auc</code></strong> :&ensp;<code>float</code></dt>
<dd>maximum perturbation from estimated auc, default 0.1</dd>
<dt><strong><code>target_auc</code></strong> :&ensp;<code>float</code></dt>
<dd>if None, using estimate current nominal auc</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>significanec level. If None use processRoc.alpha</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>minimum sample size</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def samplesize(self,
               delta_auc=0.1,
               target_auc=None,
               alpha=None):
    &#39;&#39;&#39;
    estimate sample size for atataing auc bound under given significance level

    Args:
        delta_auc (float): maximum perturbation from estimated auc, default 0.1
        target_auc (float): if None, using estimate current nominal auc
        alpha (float): significanec level. If None use processRoc.alpha

    Returns:
        float: minimum sample size
    &#39;&#39;&#39;
    if alpha is None:
        alpha=self.alpha

    if target_auc is None:
        if &#39;nominal&#39; not in self._auc.keys():
            self.auc()
        target_auc=self._auc[&#39;nominal&#39;]
        
    import scipy.stats as stats
    z=stats. norm. ppf(1 - (alpha/2))
    required_npos = (z*z)*target_auc*(1-target_auc)/(delta_auc*delta_auc)

    return required_npos</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.processRoc.scoretoprobability"><code class="name flex">
<span>def <span class="ident">scoretoprobability</span></span>(<span>self, score, regen=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Map computed score to probability of sample being in the positive class.
This is simply the PPV corresponding to the threshold which equals the score.
Now supports both single scores and lists/numpy arrays of scores.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>score</code></strong> :&ensp;<code>float</code> or <code>list</code> or <code>numpy.ndarray</code></dt>
<dd>computed score(s)</dd>
<dt><strong><code>regen</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, regenerate roc curve</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>values passed for regeneration of smoothed roc</dd>
</dl>
<h2 id="return">Return</h2>
<p>float or numpy.ndarray representing probability of being in positive cohort</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scoretoprobability(self, score, regen=True, **kwargs):
    &#39;&#39;&#39;
    Map computed score to probability of sample being in the positive class.
    This is simply the PPV corresponding to the threshold which equals the score.
    Now supports both single scores and lists/numpy arrays of scores.

    Args:
        score (float or list or numpy.ndarray): computed score(s)
        regen (bool): if True, regenerate roc curve
        kwargs (dict): values passed for regeneration of smoothed roc

    Return:
        float or numpy.ndarray representing probability of being in positive cohort
    &#39;&#39;&#39;

    if score is None:
        return None

    if regen:
        STEP = 0.01
        precision = 3
        interpolate = True

        STEP = kwargs.get(&#39;STEP&#39;, STEP)
        precision = kwargs.get(&#39;precision&#39;, precision)
        interpolate = kwargs.get(&#39;interpolate&#39;, interpolate)

        self.smooth(STEP=STEP)
        self.allmeasures(interpolate=interpolate)
        self.usample(precision=precision)

    df = self.get()
    if &#39;threshold&#39; not in df.columns:
        raise ValueError(&#39;Threshold not in columns or index&#39;)
    if &#39;ppv&#39; not in df.columns:
        raise ValueError(&#39;PPV not in columns or index&#39;)

    def compute_val(score):
        if score is None:
            return None
        if score &gt; df.threshold.max():
            val = df.ppv.values.max()
        else:
            val = df[df.threshold &gt; score].ppv.tail(1).values[0]
        return (val - df.ppv.values.min()) / (df.ppv.values.max() - df.ppv.values.min())

    if isinstance(score, (list, np.ndarray)):
        return np.array([compute_val(s) for s in score])
    else:
        return compute_val(score)</code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.processRoc.smooth"><code class="name flex">
<span>def <span class="ident">smooth</span></span>(<span>self, STEP=0.0001, interpolate=True, convexify=True)</span>
</code></dt>
<dd>
<div class="desc"><p>smooth roc curves and update processRoc.df which is accessible using processRoc.get()</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>STEP</code></strong> :&ensp;<code>float</code></dt>
<dd>smooting step, default 0.0001</dd>
<dt><strong><code>interpolate</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, interpolate missing values, default True</dd>
<dt><strong><code>convexify</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, replace ROC with convex hull, default True</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def smooth(self,
           STEP=0.0001,
           interpolate=True,
           convexify=True):
    &#39;&#39;&#39;
    smooth roc curves and update processRoc.df which is accessible using processRoc.get()

    Args:
        STEP (float): smooting step, default 0.0001
        interpolate (bool): if True, interpolate missing values, default True
        convexify (bool): if True, replace ROC with convex hull, default True
    &#39;&#39;&#39;
    self.df=self.raw_df.copy()
    VAR=self.fprcol
    df_=self.df.reset_index()
    DF=pd.concat([pd.DataFrame(
        df_[df_[VAR].between(i,i+STEP)].max()).transpose()
                  for i in np.arange(0,1,STEP)]).set_index(VAR)
    DF=DF.dropna()
    DF.loc[0]=pd.Series([],dtype=float) 
    DF.loc[1]=pd.Series([],dtype=float) 
    DF.loc[0,&#39;tpr&#39;]=0
    DF.loc[1,&#39;tpr&#39;]=1
    
    DF=DF.sort_index()
    if interpolate:
        DF=DF.interpolate(limit_direction=&#39;both&#39;,method=&#39;spline&#39;,order=self.order)
        DF[DF &lt; 0] = 0
        self.df=DF
    if convexify:
        self.__convexify()
    return </code></pre>
</details>
</dd>
<dt id="zedstat.zedstat.processRoc.usample"><code class="name flex">
<span>def <span class="ident">usample</span></span>(<span>self, df=None, precision=3)</span>
</code></dt>
<dd>
<div class="desc"><p>make performance measures estimated at regular intervals of false positive rate</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>dataframe woth performance values, fpr as index. default: None, when the dataframe entered at initialization is used</dd>
<dt><strong><code>precision</code></strong> :&ensp;<code>int</code></dt>
<dd>number of digits after decismal point used to sample fpr range</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.DataFrame</code></dt>
<dd>uniformly sampled performance dataframe</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def usample(self,
            df=None,
            precision=3):
    &#39;&#39;&#39;
    make performance measures estimated at regular intervals of false positive rate

    Args:
        df (pandas.DataFrame): dataframe woth performance values, fpr as index. default: None, when the dataframe entered at initialization is used
        precision (int): number of digits after decismal point used to sample fpr range
    
    Returns:
        pandas.DataFrame: uniformly sampled performance dataframe
    &#39;&#39;&#39;
    step=10**(-precision)
    fpr=[np.round(x,precision) for x in np.arange(0,1+step,step)]
    if df is None:        
        fpr_=[x for x in fpr if x not in self.df.index]
    else:
        fpr_=[x for x in fpr if x not in df.index]

    if df is None:
        df___=self.df.copy()
    else:
        df___=df.copy()
        
    for x in fpr_:
        df___.loc[x]=pd.Series([],dtype=float) 
    df___=df___.sort_index().interpolate()
    
    df___=df___.loc[fpr]        
    if df is None:
        self.df=df___

    return df___</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<img src="teomimlogo.png" alt="drawing" style="width:400px;"/>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="zedstat" href="index.html">zedstat</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="zedstat.zedstat.dx_prob" href="#zedstat.zedstat.dx_prob">dx_prob</a></code></li>
<li><code><a title="zedstat.zedstat.genroc" href="#zedstat.zedstat.genroc">genroc</a></code></li>
<li><code><a title="zedstat.zedstat.getEta" href="#zedstat.zedstat.getEta">getEta</a></code></li>
<li><code><a title="zedstat.zedstat.getTime" href="#zedstat.zedstat.getTime">getTime</a></code></li>
<li><code><a title="zedstat.zedstat.pipeline" href="#zedstat.zedstat.pipeline">pipeline</a></code></li>
<li><code><a title="zedstat.zedstat.s_prob" href="#zedstat.zedstat.s_prob">s_prob</a></code></li>
<li><code><a title="zedstat.zedstat.score_to_probability" href="#zedstat.zedstat.score_to_probability">score_to_probability</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="zedstat.zedstat.processRoc" href="#zedstat.zedstat.processRoc">processRoc</a></code></h4>
<ul class="two-column">
<li><code><a title="zedstat.zedstat.processRoc.allmeasures" href="#zedstat.zedstat.processRoc.allmeasures">allmeasures</a></code></li>
<li><code><a title="zedstat.zedstat.processRoc.auc" href="#zedstat.zedstat.processRoc.auc">auc</a></code></li>
<li><code><a title="zedstat.zedstat.processRoc.get" href="#zedstat.zedstat.processRoc.get">get</a></code></li>
<li><code><a title="zedstat.zedstat.processRoc.getBounds" href="#zedstat.zedstat.processRoc.getBounds">getBounds</a></code></li>
<li><code><a title="zedstat.zedstat.processRoc.interpret" href="#zedstat.zedstat.processRoc.interpret">interpret</a></code></li>
<li><code><a title="zedstat.zedstat.processRoc.nominal_auc" href="#zedstat.zedstat.processRoc.nominal_auc">nominal_auc</a></code></li>
<li><code><a title="zedstat.zedstat.processRoc.operating_zone" href="#zedstat.zedstat.processRoc.operating_zone">operating_zone</a></code></li>
<li><code><a title="zedstat.zedstat.processRoc.pvalue" href="#zedstat.zedstat.processRoc.pvalue">pvalue</a></code></li>
<li><code><a title="zedstat.zedstat.processRoc.samplesize" href="#zedstat.zedstat.processRoc.samplesize">samplesize</a></code></li>
<li><code><a title="zedstat.zedstat.processRoc.scoretoprobability" href="#zedstat.zedstat.processRoc.scoretoprobability">scoretoprobability</a></code></li>
<li><code><a title="zedstat.zedstat.processRoc.smooth" href="#zedstat.zedstat.processRoc.smooth">smooth</a></code></li>
<li><code><a title="zedstat.zedstat.processRoc.usample" href="#zedstat.zedstat.processRoc.usample">usample</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
Author: <a href="https://zed.uchicago.edu"> Zero Knowledge Discovery, University of Chicago</a>. Email: ishanu@uchicago.edu
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>